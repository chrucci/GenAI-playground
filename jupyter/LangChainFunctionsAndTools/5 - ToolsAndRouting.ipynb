{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a toy tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search\n",
      "search(query: str) -> str - Search for weather online\n",
      "{'query': {'title': 'Query', 'description': 'Thing to search for', 'type': 'string'}}\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import tool\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "class SearchInput(BaseModel):\n",
    "    query: str = Field(description=\"Thing to search for\")\n",
    "\n",
    "@tool(args_schema=SearchInput)\n",
    "def search(query: str) -> str:\n",
    "    \"\"\"Search for weather online\"\"\"\n",
    "    return f\"Searching for {query}\"\n",
    "\n",
    "print(search.name)\n",
    "print(search.description)\n",
    "print(search.args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Searching for foo bar asdf'"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search(\"foo bar asdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a real tool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weather Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_current_temperature\n",
      "get_current_temperature(latitude: float, longitude: float) -> dict - Fetch current temperature for given coordinates.\n",
      "{'latitude': {'title': 'Latitude', 'description': 'Latitude of the location to fetch weather data for', 'type': 'number'}, 'longitude': {'title': 'Longitude', 'description': 'Longitude of the location to fetch weather data for', 'type': 'number'}}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from pydantic import BaseModel, Field\n",
    "import datetime\n",
    "\n",
    "# Define the input schema\n",
    "class OpenMeteoInput(BaseModel):\n",
    "    latitude: float = Field(..., description=\"Latitude of the location to fetch weather data for\")\n",
    "    longitude: float = Field(..., description=\"Longitude of the location to fetch weather data for\")\n",
    "\n",
    "@tool(args_schema=OpenMeteoInput)\n",
    "def get_current_temperature(latitude: float, longitude: float) -> dict:\n",
    "    \"\"\"Fetch current temperature for given coordinates.\"\"\"\n",
    "    \n",
    "    BASE_URL = \"https://api.open-meteo.com/v1/forecast\"\n",
    "    \n",
    "    # Parameters for the request\n",
    "    params = {\n",
    "        'latitude': latitude,\n",
    "        'longitude': longitude,\n",
    "        'hourly': 'temperature_2m',\n",
    "        'forecast_days': 1,\n",
    "        'temperature_unit': 'fahrenheit',\n",
    "    }\n",
    "\n",
    "    # Make the request\n",
    "    response = requests.get(BASE_URL, params=params)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        results = response.json()\n",
    "    else:\n",
    "        raise Exception(f\"API Request failed with status code: {response.status_code}\")\n",
    "\n",
    "    current_utc_time = datetime.datetime.utcnow()\n",
    "    time_list = [datetime.datetime.fromisoformat(time_str.replace('Z', '+00:00')) for time_str in results['hourly']['time']]\n",
    "    temperature_list = results['hourly']['temperature_2m']\n",
    "    \n",
    "    closest_time_index = min(range(len(time_list)), key=lambda i: abs(time_list[i] - current_utc_time))\n",
    "    current_temperature = temperature_list[closest_time_index]\n",
    "    \n",
    "    return f'The current temperature is {current_temperature}°F'\n",
    "\n",
    "print(get_current_temperature.name)\n",
    "print(get_current_temperature.description)\n",
    "print(get_current_temperature.args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools.render import format_tool_to_openai_function\n",
    "temp_function = format_tool_to_openai_function(get_current_temperature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The current temperature is 36.3°F'"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_current_temperature({\"latitude\": 41.875870, \"longitude\": -72.801400})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wikipedia tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wikipedia\n",
    "@tool\n",
    "def search_wikipedia(query: str) -> str:\n",
    "    \"\"\"Run Wikipedia search and get page summaries.\"\"\"\n",
    "    page_titles = wikipedia.search(query)\n",
    "    summaries = []\n",
    "    for page_title in page_titles[: 3]:\n",
    "        try:\n",
    "            wiki_page =  wikipedia.page(title=page_title, auto_suggest=False)\n",
    "            summaries.append(f\"Page: {page_title}\\nSummary: {wiki_page.summary}\")\n",
    "        except (\n",
    "            self.wiki_client.exceptions.PageError,\n",
    "            self.wiki_client.exceptions.DisambiguationError,\n",
    "        ):\n",
    "            pass\n",
    "    if not summaries:\n",
    "        return \"No good Wikipedia Search Result was found\"\n",
    "    return \"\\n\\n\".join(summaries)\n",
    "\n",
    "wikipedia_function = format_tool_to_openai_function(search_wikipedia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Page: Zach Wilson\\nSummary: Zachary Kapono Wilson (born August 3, 1999) is an American football quarterback for the New York Jets of the National Football League (NFL). He played college football at BYU, where he was a two-time bowl game MVP, and was selected second overall by the Jets in the 2021 NFL Draft.\\n\\nPage: 2023 New York Jets season\\nSummary: The 2023 season is the New York Jets' 54th season in the National Football League (NFL), their 64th overall, their fifth under general manager Joe Douglas and their third under head coach Robert Saleh. The Jets are looking to improve on their 7–10 record from 2022. After the Seattle Mariners of Major League Baseball (MLB) clinched a playoff berth for the first time since 2001 and the Sacramento Kings of the National Basketball Association (NBA) clinched a playoff berth for first time since 2006, the Jets and the Buffalo Sabres of the National Hockey League (NHL) are now tied for the longest active playoff drought in major North American professional sports with each missing the playoffs 12 years straight. The Jets haven't made the playoffs since 2010.In the offseason, the Jets traded for 4-time league MVP Aaron Rodgers. However, disaster struck in the season opener against the Buffalo Bills when Rodgers suffered a season-ending torn Achilles tendon after just four offensive snaps. The preseason was documented on the HBO television show Hard Knocks.\\n\\nPage: David Neeleman\\nSummary: David Gary Neeleman (born October 16, 1959) is a Brazilian-American businessman. He has founded five commercial airlines: Morris Air, WestJet, JetBlue Airways, Azul Brazilian Airlines, and Breeze Airways. Along with Humberto Pedrosa and Aigle Azur, he owned 45% of TAP Air Portugal. In 2017 he became a citizen of Cyprus.\""
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_wikipedia({\"query\": \"Zach Wilson\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.openai_functions.openapi import openapi_spec_to_openai_fn\n",
    "from langchain.utilities.openapi import OpenAPISpec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "{\n",
    "  \"openapi\": \"3.1.0\",\n",
    "  \"info\": {\n",
    "    \"title\": \"Non-oAuth Scopes example\",\n",
    "    \"version\": \"1.0.0\"\n",
    "  },\n",
    "  \"paths\": {\n",
    "    \"/users\": {\n",
    "      \"get\": {\n",
    "        \"security\": [\n",
    "          {\n",
    "            \"bearerAuth\": [\n",
    "              \"read:users\",\n",
    "              \"public\"\n",
    "            ]\n",
    "          }\n",
    "        ]\n",
    "      }\n",
    "    }\n",
    "  },\n",
    "  \"components\": {\n",
    "    \"securitySchemes\": {\n",
    "      \"bearerAuth\": {\n",
    "        \"type\": \"http\",\n",
    "        \"scheme\": \"bearer\",\n",
    "        \"bearerFormat\": \"jwt\",\n",
    "        \"description\": \"note: non-oauth scopes are not defined at the securityScheme level\"\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'super' object has no attribute 'parse_obj'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/chris/Dev/GitHub/GenAI-playground/jupyter/LangChainFunctionsAndTools/5 - ToolsAndRouting.ipynb Cell 15\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/chris/Dev/GitHub/GenAI-playground/jupyter/LangChainFunctionsAndTools/5%20-%20ToolsAndRouting.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m spec \u001b[39m=\u001b[39m OpenAPISpec\u001b[39m.\u001b[39;49mfrom_text(text) \u001b[39m#I haven't been able to get this to work\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/chris/Dev/GitHub/GenAI-playground/jupyter/LangChainFunctionsAndTools/5%20-%20ToolsAndRouting.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m pet_openai_functions, pet_callables \u001b[39m=\u001b[39m openapi_spec_to_openai_fn(spec)\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/chris/Dev/GitHub/GenAI-playground/jupyter/LangChainFunctionsAndTools/5%20-%20ToolsAndRouting.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlangchain\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mchat_models\u001b[39;00m \u001b[39mimport\u001b[39;00m ChatOpenAI\n",
      "File \u001b[0;32m~/anaconda3/envs/ai-dev/lib/python3.11/site-packages/langchain/utilities/openapi.py:227\u001b[0m, in \u001b[0;36mOpenAPISpec.from_text\u001b[0;34m(cls, text)\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[39mexcept\u001b[39;00m json\u001b[39m.\u001b[39mJSONDecodeError:\n\u001b[1;32m    226\u001b[0m     spec_dict \u001b[39m=\u001b[39m yaml\u001b[39m.\u001b[39msafe_load(text)\n\u001b[0;32m--> 227\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49mfrom_spec_dict(spec_dict)\n",
      "File \u001b[0;32m~/anaconda3/envs/ai-dev/lib/python3.11/site-packages/langchain/utilities/openapi.py:218\u001b[0m, in \u001b[0;36mOpenAPISpec.from_spec_dict\u001b[0;34m(cls, spec_dict)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    216\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfrom_spec_dict\u001b[39m(\u001b[39mcls\u001b[39m, spec_dict: \u001b[39mdict\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m OpenAPISpec:\n\u001b[1;32m    217\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Get an OpenAPI spec from a dict.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 218\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49mparse_obj(spec_dict)\n",
      "File \u001b[0;32m~/anaconda3/envs/ai-dev/lib/python3.11/site-packages/langchain/utilities/openapi.py:202\u001b[0m, in \u001b[0;36mOpenAPISpec.parse_obj\u001b[0;34m(cls, obj)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    201\u001b[0m     \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_alert_unsupported_spec(obj)\n\u001b[0;32m--> 202\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mparse_obj(obj)\n\u001b[1;32m    203\u001b[0m \u001b[39mexcept\u001b[39;00m ValidationError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    204\u001b[0m     \u001b[39m# We are handling possibly misconfigured specs and\u001b[39;00m\n\u001b[1;32m    205\u001b[0m     \u001b[39m# want to do a best-effort job to get a reasonable interface out of it.\u001b[39;00m\n\u001b[1;32m    206\u001b[0m     new_obj \u001b[39m=\u001b[39m copy\u001b[39m.\u001b[39mdeepcopy(obj)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'super' object has no attribute 'parse_obj'"
     ]
    }
   ],
   "source": [
    "spec = OpenAPISpec.from_text(text) #I haven't been able to get this to work\n",
    "pet_openai_functions, pet_callables = openapi_spec_to_openai_fn(spec)\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "model = ChatOpenAI(temperature=0).bind(functions=pet_openai_functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.invoke(\"what are three pets names\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.invoke(\"tell me about pet with id 42\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Routing\n",
    "\n",
    "In lesson 3, we show an example of function calling deciding between two candidate functions.\n",
    "\n",
    "Given our tools above, let's format these as OpenAI functions and show this same behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "functions = [\n",
    "    format_tool_to_openai_function(f) for f in [\n",
    "        search_wikipedia, get_current_temperature\n",
    "    ]\n",
    "]\n",
    "model = ChatOpenAI(temperature=0).bind(functions=functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'function_call': {'name': 'get_current_temperature', 'arguments': '{\\n  \"latitude\": 37.7749,\\n  \"longitude\": -122.4194\\n}'}})"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prompt for weather it will use the weather function\n",
    "model.invoke(\"what is the weather in SF right now?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'function_call': {'name': 'search_wikipedia', 'arguments': '{\\n  \"query\": \"langchain\"\\n}'}})"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prompt for fact it will use the wikipedia function\n",
    "model.invoke(\"what is langchain\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are helpful but sassy assistant\"),\n",
    "    (\"user\", \"{input}\"),\n",
    "])\n",
    "chain = prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'function_call': {'name': 'get_current_temperature', 'arguments': '{\\n  \"latitude\": 37.7749,\\n  \"longitude\": -122.4194\\n}'}})"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"input\": \"what is the weather in sf right now\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain.schema.agent.AgentActionMessageLog'>\n",
      "<class 'langchain.schema.agent.AgentActionMessageLog'>\n",
      "<class 'langchain.schema.agent.AgentFinish'>\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents.output_parsers import OpenAIFunctionsAgentOutputParser\n",
    "chain = prompt | model | OpenAIFunctionsAgentOutputParser()\n",
    "weather_result = chain.invoke({\"input\": \"what is the weather in sf right now\"})\n",
    "print(type(weather_result))\n",
    "wiki_result = chain.invoke({\"input\": \"what is langchain\"})\n",
    "print(type(wiki_result))\n",
    "regular_result = chain.invoke({\"input\": \"tell me a joke\"})\n",
    "print(type(regular_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'get_current_temperature'"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_result.tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'latitude': 37.7749, 'longitude': -122.4194}"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_result.tool_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The current temperature is 63.2°F'"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_current_temperature(weather_result.tool_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Page: LangChain\\nSummary: LangChain is a framework designed to simplify the creation of applications using large language models (LLMs). As a language model integration framework, LangChain\\'s use-cases largely overlap with those of language models in general, including document analysis and summarization, chatbots, and code analysis.\\n\\nPage: Prompt engineering\\nSummary: Prompt engineering is the process of structuring text that can be interpreted and understood by a generative AI model. A prompt is natural language text describing the task that an AI should perform.A prompt for a text-to-text model can be a query such as \"what is Fermat\\'s little theorem?\", a command such as \"write a poem about leaves falling\", a short statement of feedback (for example, \"too verbose\", \"too formal\", \"rephrase again\", \"omit this word\") or a longer statement including context, instructions, and input data. Prompt engineering may involve phrasing a query, specifying a style, providing relevant context or assigning a role to the AI such as \"Act as a native French speaker\". A prompt may include a few examples for a model to learn from, such as \"maison -> house, chat -> cat, chien ->\", an approach called few-shot learning.When communicating with a text-to-image or a text-to-audio model, a typical prompt is a description of a desired output such as \"a high-quality photo of an astronaut riding a horse\" or \"Lo-fi slow BPM electro chill with organic samples\". Prompting a text-to-image model may involve adding, removing, emphasizing and re-ordering words to achieve a desired subject, style, layout, lighting, and aesthetic.\\n\\nPage: Sentence embedding\\nSummary: In natural language processing, a sentence embedding refers to a numeric representation of a sentence in the form of a vector of real numbers which encodes meaningful semantic information.State of the art embeddings are based on the learned hidden layer representation of dedicated sentence transformer models. BERT pioneered an approach involving the use of a dedicated [CLS] token prepended to the beginning of each sentence inputted into the model; the final hidden state vector of this token encodes information about the sentence and can be fine-tuned for use in sentence classification tasks. In practice however, BERT\\'s sentence embedding with the [CLS] token achieves poor performance, often worse than simply averaging non-contextual word embeddings. SBERT later achieved superior sentence embedding performance by fine tuning BERT\\'s [CLS] token embeddings through the usage of a siamese neural network architecture on the SNLI dataset. \\nOther approaches are loosely based on the idea of distributional semantics applied to sentences. Skip-Thought trains an encoder-decoder structure for the task of neighboring sentences predictions. Though this has been shown to achieve worse performance than approaches such as InferSent or SBERT. \\nAn alternative direction is to aggregate word embeddings, such as those returned by Word2vec, into sentence embeddings. The most straightforward approach is to simply compute the average of word vectors, known as continuous bag-of-words (CBOW). However, more elaborate solutions based on word vector quantization have also been proposed. One such approach is the vector of locally aggregated word embeddings (VLAWE), which demonstrated performance improvements in downstream text classification tasks.'"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_wikipedia(wiki_result.tool_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'output': \"Sure, here's a joke for you:\\n\\nWhy don't scientists trust atoms?\\n\\nBecause they make up everything!\"}"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regular_result.return_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this seems like a hack.  Why can't this be polymorphic?\n",
    "\n",
    "from langchain.schema.agent import AgentFinish\n",
    "def route(result):\n",
    "    if isinstance(result, AgentFinish):\n",
    "        return result.return_values['output']\n",
    "    else:\n",
    "        tools = {\n",
    "            \"search_wikipedia\": search_wikipedia, \n",
    "            \"get_current_temperature\": get_current_temperature,\n",
    "        }\n",
    "        return tools[result.tool].run(result.tool_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | model | OpenAIFunctionsAgentOutputParser() | route"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The current temperature is 63.2°F'"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"input\": \"What is the weather in san francisco right now?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Page: LangChain\\nSummary: LangChain is a framework designed to simplify the creation of applications using large language models (LLMs). As a language model integration framework, LangChain\\'s use-cases largely overlap with those of language models in general, including document analysis and summarization, chatbots, and code analysis.\\n\\nPage: Prompt engineering\\nSummary: Prompt engineering is the process of structuring text that can be interpreted and understood by a generative AI model. A prompt is natural language text describing the task that an AI should perform.A prompt for a text-to-text model can be a query such as \"what is Fermat\\'s little theorem?\", a command such as \"write a poem about leaves falling\", a short statement of feedback (for example, \"too verbose\", \"too formal\", \"rephrase again\", \"omit this word\") or a longer statement including context, instructions, and input data. Prompt engineering may involve phrasing a query, specifying a style, providing relevant context or assigning a role to the AI such as \"Act as a native French speaker\". A prompt may include a few examples for a model to learn from, such as \"maison -> house, chat -> cat, chien ->\", an approach called few-shot learning.When communicating with a text-to-image or a text-to-audio model, a typical prompt is a description of a desired output such as \"a high-quality photo of an astronaut riding a horse\" or \"Lo-fi slow BPM electro chill with organic samples\". Prompting a text-to-image model may involve adding, removing, emphasizing and re-ordering words to achieve a desired subject, style, layout, lighting, and aesthetic.\\n\\nPage: Sentence embedding\\nSummary: In natural language processing, a sentence embedding refers to a numeric representation of a sentence in the form of a vector of real numbers which encodes meaningful semantic information.State of the art embeddings are based on the learned hidden layer representation of dedicated sentence transformer models. BERT pioneered an approach involving the use of a dedicated [CLS] token prepended to the beginning of each sentence inputted into the model; the final hidden state vector of this token encodes information about the sentence and can be fine-tuned for use in sentence classification tasks. In practice however, BERT\\'s sentence embedding with the [CLS] token achieves poor performance, often worse than simply averaging non-contextual word embeddings. SBERT later achieved superior sentence embedding performance by fine tuning BERT\\'s [CLS] token embeddings through the usage of a siamese neural network architecture on the SNLI dataset. \\nOther approaches are loosely based on the idea of distributional semantics applied to sentences. Skip-Thought trains an encoder-decoder structure for the task of neighboring sentences predictions. Though this has been shown to achieve worse performance than approaches such as InferSent or SBERT. \\nAn alternative direction is to aggregate word embeddings, such as those returned by Word2vec, into sentence embeddings. The most straightforward approach is to simply compute the average of word vectors, known as continuous bag-of-words (CBOW). However, more elaborate solutions based on word vector quantization have also been proposed. One such approach is the vector of locally aggregated word embeddings (VLAWE), which demonstrated performance improvements in downstream text classification tasks.'"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"input\": \"What is langchain?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Sure, here's a joke for you:\\n\\nWhy don't scientists trust atoms?\\n\\nBecause they make up everything!\""
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"input\": \"tell me a joke!\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
