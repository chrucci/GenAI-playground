{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d8a2268-871d-46ad-9380-15579f53d341",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../..\")\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "_ = load_dotenv(find_dotenv())  # read local .env file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a31bbcc8-d22f-4901-9a29-ba4e5602d3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ad7a7c-8eb3-408e-9997-da12f83fafc5",
   "metadata": {},
   "source": [
    "### Explore the available models\n",
    "https://platform.openai.com/docs/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c2393a6f-a40e-40f1-ae04-566c7bbfc7bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text-search-babbage-doc-001\n",
      "curie-search-query\n",
      "text-search-babbage-query-001\n",
      "babbage\n",
      "babbage-search-query\n",
      "text-babbage-001\n",
      "text-similarity-davinci-001\n",
      "davinci\n",
      "davinci-similarity\n",
      "code-davinci-edit-001\n",
      "curie-similarity\n",
      "babbage-search-document\n",
      "curie-instruct-beta\n",
      "text-search-ada-doc-001\n",
      "davinci-instruct-beta\n",
      "text-similarity-babbage-001\n",
      "text-search-davinci-doc-001\n",
      "gpt-4-0314\n",
      "babbage-similarity\n",
      "davinci-search-query\n",
      "text-similarity-curie-001\n",
      "text-davinci-001\n",
      "text-search-davinci-query-001\n",
      "ada-search-document\n",
      "ada-code-search-code\n",
      "babbage-002\n",
      "gpt-4-0613\n",
      "gpt-4\n",
      "davinci-002\n",
      "davinci-search-document\n",
      "curie-search-document\n",
      "babbage-code-search-code\n",
      "text-search-ada-query-001\n",
      "code-search-ada-text-001\n",
      "gpt-3.5-turbo-instruct-0914\n",
      "gpt-3.5-turbo-instruct\n",
      "babbage-code-search-text\n",
      "code-search-babbage-code-001\n",
      "ada-search-query\n",
      "ada-code-search-text\n",
      "text-search-curie-query-001\n",
      "text-davinci-002\n",
      "text-embedding-ada-002\n",
      "text-davinci-edit-001\n",
      "code-search-babbage-text-001\n",
      "ada\n",
      "whisper-1\n",
      "text-ada-001\n",
      "ada-similarity\n",
      "code-search-ada-code-001\n",
      "text-similarity-ada-001\n",
      "gpt-3.5-turbo-0301\n",
      "gpt-3.5-turbo\n",
      "gpt-3.5-turbo-16k\n",
      "text-search-curie-doc-001\n",
      "gpt-3.5-turbo-16k-0613\n",
      "text-davinci-003\n",
      "text-curie-001\n",
      "curie\n",
      "gpt-3.5-turbo-0613\n"
     ]
    }
   ],
   "source": [
    "# len(openai.Model.list())\n",
    "for model in openai.Model.list()[\"data\"]:\n",
    "    print(model[\"id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dad1651-32c5-4103-9299-10693a57bf4c",
   "metadata": {},
   "source": [
    "#### helper function to generate text\n",
    "\n",
    "- The `@retry` decorator helps you to retry the API call if it fails.\n",
    "- We set the temperature to 0.0 so that the model returns the same output (completion) if given the same input (the prompt)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1f798a2c-7ca9-48a3-a069-031a8433f35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# not sure which model to use.  Currenlty condiering \"code-davinci-edit-001\" or \"gpt-3.5-turbo\"\n",
    "\n",
    "default_system_message = \"You are an expert at writing clear, concise, Python code.\"\n",
    "\n",
    "# def generate_text(prompt,\n",
    "#                     model=\"gpt-3.5-turbo\",\n",
    "#                     temperature=0,\n",
    "#                     max_tokens=500,\n",
    "#                     system_message=default_system_message):\n",
    "#     messages =  [\n",
    "#         {'role':'system',\n",
    "#         'content': system_message},\n",
    "#         {'role':'user',\n",
    "#         'content': prompt},\n",
    "#         ]\n",
    "#     response = openai.Completion.create(\n",
    "#         model=model,\n",
    "#         messages=messages,\n",
    "#         temperature=temperature,\n",
    "#         max_tokens=max_tokens,\n",
    "#     )\n",
    "#     return response.choices[0].message[\"content\"]\n",
    "\n",
    "\n",
    "def generate_chat(prompt, model=\"gpt-3.5-turbo\", temperature=0, max_tokens=500):\n",
    "    # messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    system_message = \"You are an expert at writing clear, concise, Python code.\"\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": prompt},\n",
    "    ]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature,\n",
    "        max_tokens=max_tokens,\n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]\n",
    "\n",
    "\n",
    "def generate_text(\n",
    "    prompt, model=\"gpt-3.5-turbo-instruct\", temperature=0, max_tokens=500\n",
    "):\n",
    "    # messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    system_message = \"You are an expert at writing clear, concise, Python code.\"\n",
    "    # messages =  [\n",
    "    #     {'role':'system',\n",
    "    #     'content': system_message},\n",
    "    #     {'role':'user',\n",
    "    #     'content': prompt},\n",
    "    #     ]\n",
    "    response = openai.Completion.create(\n",
    "        model=model,\n",
    "        prompt=f\"{system_message}\\n\\n{prompt}\",\n",
    "        temperature=temperature,\n",
    "        max_tokens=max_tokens,\n",
    "    )\n",
    "    return response.choices[0].text  # this is different from Chat above"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b71a9d-be97-482a-b06d-02821c8d7127",
   "metadata": {},
   "source": [
    "#### Ask the LLM how to write some code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "58a31b53-8904-4571-95db-12531aef202c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Certainly! Here's an example of how to iterate over a list in Python:\n",
      "\n",
      "```python\n",
      "my_list = [1, 2, 3, 4, 5]\n",
      "\n",
      "for item in my_list:\n",
      "    print(item)\n",
      "```\n",
      "\n",
      "In this example, we have a list called `my_list` with five elements. We use a `for` loop to iterate over each item in the list. The loop variable `item` takes on the value of each element in the list, one at a time. Inside the loop, we can perform any desired operations on each item. In this case, we simply print each item to the console.\n",
      "\n",
      "The output of this code will be:\n",
      "\n",
      "```\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "```\n",
      "\n",
      "You can replace the `print(item)` line with any other code you want to execute for each item in the list.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Show me how to iterate over a list.\"\n",
    "\n",
    "completion = generate_chat(prompt)\n",
    "print(completion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "48ef2504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "To iterate over a list in Python, you can use a for loop. Here is an example:\n",
      "\n",
      "my_list = [1, 2, 3, 4, 5]\n",
      "\n",
      "for item in my_list:\n",
      "    print(item)\n",
      "\n",
      "# Output: 1\n",
      "#         2\n",
      "#         3\n",
      "#         4\n",
      "#         5\n",
      "\n",
      "In this example, we have a list called \"my_list\" with five elements. We use a for loop to iterate over each element in the list and print it out. The variable \"item\" represents each element in the list as we loop through it.\n",
      "\n",
      "You can also use the range() function to iterate over a list. Here is an example:\n",
      "\n",
      "my_list = [1, 2, 3, 4, 5]\n",
      "\n",
      "for i in range(len(my_list)):\n",
      "    print(my_list[i])\n",
      "\n",
      "# Output: 1\n",
      "#         2\n",
      "#         3\n",
      "#         4\n",
      "#         5\n",
      "\n",
      "In this example, we use the range() function to generate a sequence of numbers from 0 to the length of the list. We then use this sequence as the index to access each element in the list and print it out.\n",
      "\n",
      "Another way to iterate over a list is by using a while loop. Here is an example:\n",
      "\n",
      "my_list = [1, 2, 3, 4, 5]\n",
      "i = 0\n",
      "\n",
      "while i < len(my_list):\n",
      "    print(my_list[i])\n",
      "    i += 1\n",
      "\n",
      "# Output: 1\n",
      "#         2\n",
      "#         3\n",
      "#         4\n",
      "#         5\n",
      "\n",
      "In this example, we use a while loop to iterate over the list. The variable \"i\" is used as the index to access each element in the list. We increment \"i\" by 1 in each iteration until it reaches the length of the list.\n",
      "\n",
      "These are some ways to iterate over a list in Python. Depending on your specific needs, you can choose the most suitable method for your code.\n"
     ]
    }
   ],
   "source": [
    "completion = generate_text(prompt)\n",
    "print(completion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6628d845-0b17-400d-809a-78c43e84ff03",
   "metadata": {},
   "source": [
    "#### Try out the code\n",
    "- Try copy-pasting some of the generated code and running it in the notebook.\n",
    "- Remember to test out the LLM-generated code and debug it make sure it works as intended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "03575f11-4579-4f03-bb42-ac8a9f3b0ba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "# Define a list\n",
    "my_list = [1, 2, 3, 4, 5]\n",
    "\n",
    "# Iterate over each element in the list\n",
    "for item in my_list:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e53956-0969-4d41-9db7-40a03050a018",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
