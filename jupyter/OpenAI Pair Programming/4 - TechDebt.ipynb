{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8240033f-cfb2-44c3-b94f-5e53874a1e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../..')\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33be108b-00f8-4293-9ea1-57942c6fabec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "openai.api_key  = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6e9f436-20b4-4c5d-96f8-1ddb6f5d03e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(prompt, \n",
    "                    model=\"gpt-3.5-turbo\", \n",
    "                    temperature=0, \n",
    "                    max_tokens=500,\n",
    "                    system_message=\"You are an expert at writing clear, concise, Python code.\"):\n",
    "    # messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    messages =  [  \n",
    "        {'role':'system', \n",
    "        'content': system_message},    \n",
    "        {'role':'user', \n",
    "        'content': prompt},  \n",
    "        ] \n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature, \n",
    "        max_tokens=max_tokens,\n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]\n",
    "\n",
    "def generate_and_print(prompt, \n",
    "                    model=\"gpt-3.5-turbo\", \n",
    "                    temperature=0, \n",
    "                    max_tokens=500,\n",
    "                    system_message=\"You are an expert at writing clear, concise, Python code.\"):\n",
    "    completion = generate_text(prompt, \n",
    "                                model=model, \n",
    "                                temperature=temperature, \n",
    "                                max_tokens=max_tokens, \n",
    "                                system_message=system_message)\n",
    "    print(completion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9232a012-52cf-493c-b37c-13e44cb1ed1f",
   "metadata": {},
   "source": [
    "### Ask an LLM to explain a complex code base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "792ad143-e9b7-43f3-b6d8-e1c0cbefa3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Complex Code Block\n",
    "# Note: Taken from https://github.com/lmoroney/odmlbook/blob/63c0825094b2f44efc5c4d3226425a51990e73d6/BookSource/Chapter08/ios/cats_vs_dogs/CatVsDogClassifierSample/ModelDataHandler/ModelDataHandler.swift\n",
    "CODE_BLOCK = \"\"\"\n",
    "// Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n",
    "//\n",
    "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "// you may not use this file except in compliance with the License.\n",
    "// You may obtain a copy of the License at\n",
    "//\n",
    "//    http://www.apache.org/licenses/LICENSE-2.0\n",
    "//\n",
    "// Unless required by applicable law or agreed to in writing, software\n",
    "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "// See the License for the specific language governing permissions and\n",
    "// limitations under the License.\n",
    "\n",
    "import CoreImage\n",
    "import TensorFlowLite\n",
    "import UIKit\n",
    "\n",
    "\n",
    "/// An inference from invoking the `Interpreter`.\n",
    "struct Inference {\n",
    "  let confidence: Float\n",
    "  let label: String\n",
    "}\n",
    "\n",
    "/// Information about a model file or labels file.\n",
    "typealias FileInfo = (name: String, extension: String)\n",
    "\n",
    "/// Information about the MobileNet model.\n",
    "enum MobileNet {\n",
    "  static let modelInfo: FileInfo = (name: \"converted_model\", extension: \"tflite\")\n",
    "}\n",
    "\n",
    "/// This class handles all data preprocessing and makes calls to run inference on a given frame\n",
    "/// by invoking the `Interpreter`. It then formats the inferences obtained and returns the top N\n",
    "/// results for a successful inference.\n",
    "class ModelDataHandler {\n",
    "\n",
    "  // MARK: - Public Properties\n",
    "\n",
    "  /// The current thread count used by the TensorFlow Lite Interpreter.\n",
    "  let threadCount: Int\n",
    "\n",
    "  let resultCount = 1\n",
    "\n",
    "  // MARK: - Model Parameters\n",
    "\n",
    "  let batchSize = 1\n",
    "  let inputChannels = 3\n",
    "  let inputWidth = 224\n",
    "  let inputHeight = 224\n",
    "\n",
    "  // MARK: - Private Properties\n",
    "\n",
    "  /// List of labels from the given labels file.\n",
    "  private var labels: [String] = [\"Cat\", \"Dog\"]\n",
    "\n",
    "  /// TensorFlow Lite `Interpreter` object for performing inference on a given model.\n",
    "  private var interpreter: Interpreter\n",
    "\n",
    "  /// Information about the alpha component in RGBA data.\n",
    "  private let alphaComponent = (baseOffset: 4, moduloRemainder: 3)\n",
    "\n",
    "  // MARK: - Initialization\n",
    "\n",
    "  /// A failable initializer for `ModelDataHandler`. A new instance is created if the model and\n",
    "  /// labels files are successfully loaded from the app's main bundle. Default `threadCount` is 1.\n",
    "  init?(modelFileInfo: FileInfo, threadCount: Int = 1) {\n",
    "    let modelFilename = modelFileInfo.name\n",
    "\n",
    "    // Construct the path to the model file.\n",
    "    guard let modelPath = Bundle.main.path(\n",
    "      forResource: modelFilename,\n",
    "      ofType: modelFileInfo.extension\n",
    "      ) else {\n",
    "        print(\"Failed to load the model file with name: \\(modelFilename).\")\n",
    "        return nil\n",
    "    }\n",
    "\n",
    "    // Specify the options for the `Interpreter`.\n",
    "    self.threadCount = threadCount\n",
    "    var options = InterpreterOptions()\n",
    "    options.threadCount = threadCount\n",
    "    do {\n",
    "      // Create the `Interpreter`.\n",
    "      interpreter = try Interpreter(modelPath: modelPath, options: options)\n",
    "    } catch let error {\n",
    "      print(\"Failed to create the interpreter with error: \\(error.localizedDescription)\")\n",
    "      return nil\n",
    "    }\n",
    "\n",
    "  }\n",
    "\n",
    "  // MARK: - Public Methods\n",
    "\n",
    "  /// Performs image preprocessing, invokes the `Interpreter`, and process the inference results.\n",
    "  func runModel(onFrame pixelBuffer: CVPixelBuffer) -> [Inference]? {\n",
    "    let sourcePixelFormat = CVPixelBufferGetPixelFormatType(pixelBuffer)\n",
    "    assert(sourcePixelFormat == kCVPixelFormatType_32ARGB ||\n",
    "      sourcePixelFormat == kCVPixelFormatType_32BGRA ||\n",
    "      sourcePixelFormat == kCVPixelFormatType_32RGBA)\n",
    "\n",
    "\n",
    "    let imageChannels = 4\n",
    "    assert(imageChannels >= inputChannels)\n",
    "\n",
    "    // Crops the image to the biggest square in the center and scales it down to model dimensions.\n",
    "    let scaledSize = CGSize(width: inputWidth, height: inputHeight)\n",
    "    guard let thumbnailPixelBuffer = pixelBuffer.centerThumbnail(ofSize: scaledSize) else {\n",
    "      return nil\n",
    "    }\n",
    "\n",
    "    let outputTensor: Tensor\n",
    "    do {\n",
    "      // Allocate memory for the model's input `Tensor`s.\n",
    "      try interpreter.allocateTensors()\n",
    "\n",
    "      // Remove the alpha component from the image buffer to get the RGB data.\n",
    "      guard let rgbData = rgbDataFromBuffer(\n",
    "        thumbnailPixelBuffer,\n",
    "        byteCount: batchSize * inputWidth * inputHeight * inputChannels\n",
    "        ) else {\n",
    "          print(\"Failed to convert the image buffer to RGB data.\")\n",
    "          return nil\n",
    "      }\n",
    "\n",
    "      // Copy the RGB data to the input `Tensor`.\n",
    "      try interpreter.copy(rgbData, toInputAt: 0)\n",
    "\n",
    "      // Run inference by invoking the `Interpreter`.\n",
    "      try interpreter.invoke()\n",
    "\n",
    "      // Get the output `Tensor` to process the inference results.\n",
    "      outputTensor = try interpreter.output(at: 0)\n",
    "    } catch let error {\n",
    "      print(\"Failed to invoke the interpreter with error: \\(error.localizedDescription)\")\n",
    "      return nil\n",
    "    }\n",
    "\n",
    "    let results = [Float32](unsafeData: outputTensor.data) ?? []\n",
    "\n",
    "    // Process the results.\n",
    "    let topNInferences = getTopN(results: results)\n",
    "\n",
    "    // Return the inference time and inference results.\n",
    "    return topNInferences\n",
    "  }\n",
    "\n",
    "  // MARK: - Private Methods\n",
    "\n",
    "  /// Returns the top N inference results sorted in descending order.\n",
    "  private func getTopN(results: [Float]) -> [Inference] {\n",
    "    // Create a zipped array of tuples [(labelIndex: Int, confidence: Float)].\n",
    "    let zippedResults = zip(labels.indices, results)\n",
    "\n",
    "    // Sort the zipped results by confidence value in descending order.\n",
    "    let sortedResults = zippedResults.sorted { $0.1 > $1.1 }.prefix(resultCount)\n",
    "\n",
    "    // Return the `Inference` results.\n",
    "    return sortedResults.map { result in Inference(confidence: result.1, label: labels[result.0]) }\n",
    "  }\n",
    "\n",
    "  /// Loads the labels from the labels file and stores them in the `labels` property.\n",
    "  private func loadLabels(fileInfo: FileInfo) {\n",
    "    let filename = fileInfo.name\n",
    "    let fileExtension = fileInfo.extension\n",
    "    guard let fileURL = Bundle.main.url(forResource: filename, withExtension: fileExtension) else {\n",
    "      fatalError(\"Labels file not found in bundle. Please add a labels file with name \" +\n",
    "        \"\\(filename).\\(fileExtension) and try again.\")\n",
    "    }\n",
    "    do {\n",
    "      let contents = try String(contentsOf: fileURL, encoding: .utf8)\n",
    "      labels = contents.components(separatedBy: .newlines)\n",
    "    } catch {\n",
    "      fatalError(\"Labels file named \\(filename).\\(fileExtension) cannot be read. Please add a \" +\n",
    "        \"valid labels file and try again.\")\n",
    "    }\n",
    "  }\n",
    "\n",
    "  /// Returns the RGB data representation of the given image buffer with the specified `byteCount`.\n",
    "  ///\n",
    "  /// - Parameters\n",
    "  ///   - buffer: The pixel buffer to convert to RGB data.\n",
    "  ///   - byteCount: The expected byte count for the RGB data calculated using the values that the\n",
    "  ///       model was trained on: `batchSize * imageWidth * imageHeight * componentsCount`.\n",
    "  ///   - isModelQuantized: Whether the model is quantized (i.e. fixed point values rather than\n",
    "  ///       floating point values).\n",
    "  /// - Returns: The RGB data representation of the image buffer or `nil` if the buffer could not be\n",
    "  ///     converted.\n",
    "  private func rgbDataFromBuffer(\n",
    "    _ buffer: CVPixelBuffer,\n",
    "    byteCount: Int\n",
    "    ) -> Data? {\n",
    "    CVPixelBufferLockBaseAddress(buffer, .readOnly)\n",
    "    defer { CVPixelBufferUnlockBaseAddress(buffer, .readOnly) }\n",
    "    guard let mutableRawPointer = CVPixelBufferGetBaseAddress(buffer) else {\n",
    "      return nil\n",
    "    }\n",
    "    let count = CVPixelBufferGetDataSize(buffer)\n",
    "    let bufferData = Data(bytesNoCopy: mutableRawPointer, count: count, deallocator: .none)\n",
    "    var rgbBytes = [Float](repeating: 0, count: byteCount)\n",
    "    var index = 0\n",
    "    for component in bufferData.enumerated() {\n",
    "      let offset = component.offset\n",
    "      let isAlphaComponent = (offset % alphaComponent.baseOffset) == alphaComponent.moduloRemainder\n",
    "      guard !isAlphaComponent else { continue }\n",
    "      rgbBytes[index] = Float(component.element) / 255.0\n",
    "      index += 1\n",
    "    }\n",
    "\n",
    "    return rgbBytes.withUnsafeBufferPointer(Data.init)\n",
    "\n",
    "  }\n",
    "}\n",
    "\n",
    "// MARK: - Extensions\n",
    "\n",
    "extension Data {\n",
    "  /// Creates a new buffer by copying the buffer pointer of the given array.\n",
    "  ///\n",
    "  /// - Warning: The given array's element type `T` must be trivial in that it can be copied bit\n",
    "  ///     for bit with no indirection or reference-counting operations; otherwise, reinterpreting\n",
    "  ///     data from the resulting buffer has undefined behavior.\n",
    "  /// - Parameter array: An array with elements of type `T`.\n",
    "  init<T>(copyingBufferOf array: [T]) {\n",
    "    self = array.withUnsafeBufferPointer(Data.init)\n",
    "  }\n",
    "}\n",
    "\n",
    "extension Array {\n",
    "  /// Creates a new array from the bytes of the given unsafe data.\n",
    "  ///\n",
    "  /// - Warning: The array's `Element` type must be trivial in that it can be copied bit for bit\n",
    "  ///     with no indirection or reference-counting operations; otherwise, copying the raw bytes in\n",
    "  ///     the `unsafeData`'s buffer to a new array returns an unsafe copy.\n",
    "  /// - Note: Returns `nil` if `unsafeData.count` is not a multiple of\n",
    "  ///     `MemoryLayout<Element>.stride`.\n",
    "  /// - Parameter unsafeData: The data containing the bytes to turn into an array.\n",
    "  init?(unsafeData: Data) {\n",
    "\n",
    "    guard unsafeData.count % MemoryLayout<Element>.stride == 0 else { return nil }\n",
    "    #if swift(>=5.0)\n",
    "    self = unsafeData.withUnsafeBytes { .init($0.bindMemory(to: Element.self)) }\n",
    "    #else\n",
    "    self = unsafeData.withUnsafeBytes {\n",
    "      .init(UnsafeBufferPointer<Element>(\n",
    "        start: $0,\n",
    "        count: unsafeData.count / MemoryLayout<Element>.stride\n",
    "      ))\n",
    "    }\n",
    "    #endif  // swift(>=5.0)\n",
    "  }\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34fd69ce-85ed-4e97-98ee-397cde1de317",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys_message=\"Can you please explain how this code works?\"\n",
    "prompt_template = \"\"\"\n",
    "{question}\n",
    "\n",
    "Use a lot of detail and make it as clear as possible.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e04110f-536e-4709-86bc-46836c03fcba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This code is a Swift implementation of a model data handler for performing inference on a machine learning model using TensorFlow Lite. Let's go through the code step by step to understand how it works.\n",
      "\n",
      "1. The code starts with some copyright information and license details.\n",
      "\n",
      "2. It imports the necessary frameworks and libraries: CoreImage, TensorFlowLite, and UIKit.\n",
      "\n",
      "3. It defines a struct called `Inference` which represents the result of an inference. It contains two properties: `confidence` (a Float value representing the confidence score of the inference) and `label` (a String representing the label/classification of the inference).\n",
      "\n",
      "4. It defines a typealias called `FileInfo` which represents the name and extension of a file.\n",
      "\n",
      "5. It defines an enum called `MobileNet` which contains information about the MobileNet model. In this case, it only contains the model file name and extension.\n",
      "\n",
      "6. It defines a class called `ModelDataHandler` which handles all data preprocessing and inference operations. Let's go through the important parts of this class:\n",
      "\n",
      "   - Public Properties:\n",
      "     - `threadCount`: The current thread count used by the TensorFlow Lite Interpreter.\n",
      "     - `resultCount`: The number of top results to return after inference.\n",
      "\n",
      "   - Model Parameters:\n",
      "     - `batchSize`: The batch size used for inference.\n",
      "     - `inputChannels`: The number of input channels in the model.\n",
      "     - `inputWidth`: The width of the input image expected by the model.\n",
      "     - `inputHeight`: The height of the input image expected by the model.\n",
      "\n",
      "   - Private Properties:\n",
      "     - `labels`: A list of labels from the labels file.\n",
      "     - `interpreter`: The TensorFlow Lite `Interpreter` object for performing inference.\n",
      "\n",
      "   - Initialization:\n",
      "     - The initializer takes in a `modelFileInfo` parameter which represents the model file information (name and extension) and an optional `threadCount` parameter which specifies the number of threads to be used by the interpreter. It tries to load the model file from the app's main bundle and creates an interpreter object with the specified thread count.\n",
      "\n",
      "   - Public Methods:\n",
      "     - `runModel(onFrame pixelBuffer: CVPixelBuffer) -> [Inference]?`: This method performs image preprocessing, invokes the interpreter, and processes the inference results. It takes in a `pixelBuffer` parameter which represents the input image frame. It returns an array of `Inference` objects representing the top N results of the inference.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "generate_and_print(\n",
    "    prompt = prompt_template.format(question=CODE_BLOCK),\n",
    "    system_message=sys_message,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f87dbb-0bc6-484c-a000-809920dafc71",
   "metadata": {},
   "source": [
    "### Ask an LLM to document a complex code base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "abb5df8d-ea2f-4d15-9802-11d8de1c9c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys_message=\"\"\"Please write technical documentation for this code and \\n\n",
    "make it easy for a non swift developer to understand:\"\"\"\n",
    "prompt_template = \"\"\"\n",
    "{question}\n",
    "\n",
    "Output the results in markdown\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84944fb5-5095-478c-82b6-9ec224a91e7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Code Documentation\n",
      "\n",
      "## Introduction\n",
      "This code is a Swift implementation of a model data handler for performing image classification using a pre-trained MobileNet model. It handles data preprocessing, runs inference on a given frame, and processes the inference results.\n",
      "\n",
      "## Classes and Structs\n",
      "\n",
      "### Inference\n",
      "- `Inference` is a struct that represents the result of invoking the `Interpreter`. It contains the confidence score and label of the predicted class.\n",
      "\n",
      "### FileInfo\n",
      "- `FileInfo` is a typealias for a tuple that represents information about a model file or labels file. It consists of a name and an extension.\n",
      "\n",
      "### MobileNet\n",
      "- `MobileNet` is an enum that provides information about the MobileNet model. It includes the model file name and extension.\n",
      "\n",
      "### ModelDataHandler\n",
      "- `ModelDataHandler` is a class that handles all data preprocessing and inference operations. It loads the model and labels files, runs inference on a given frame, and processes the results.\n",
      "\n",
      "#### Public Properties\n",
      "- `threadCount`: The current thread count used by the TensorFlow Lite Interpreter.\n",
      "- `resultCount`: The number of top results to return.\n",
      "\n",
      "#### Model Parameters\n",
      "- `batchSize`: The batch size used for inference.\n",
      "- `inputChannels`: The number of input channels in the model.\n",
      "- `inputWidth`: The width of the input image.\n",
      "- `inputHeight`: The height of the input image.\n",
      "\n",
      "#### Private Properties\n",
      "- `labels`: A list of labels from the labels file.\n",
      "- `interpreter`: The TensorFlow Lite `Interpreter` object for performing inference.\n",
      "- `alphaComponent`: Information about the alpha component in RGBA data.\n",
      "\n",
      "#### Initialization\n",
      "- `init?(modelFileInfo: FileInfo, threadCount: Int = 1)`: Initializes a new instance of `ModelDataHandler` with the specified model file info and thread count. It loads the model file and creates the `Interpreter` object.\n",
      "\n",
      "#### Public Methods\n",
      "- `runModel(onFrame pixelBuffer: CVPixelBuffer) -> [Inference]?`: Performs image preprocessing, runs inference on the given frame, and processes the inference results. It returns an array of `Inference` objects representing the top N results.\n",
      "\n",
      "#### Private Methods\n",
      "- `getTopN(results: [Float]) -> [Inference]`: Returns the top N inference results sorted in descending order.\n",
      "- `loadLabels(fileInfo: FileInfo)`: Loads the labels from the labels file and stores them in the `labels` property.\n",
      "- `rgbData\n"
     ]
    }
   ],
   "source": [
    "generate_and_print(\n",
    "    prompt = prompt_template.format(question=CODE_BLOCK),\n",
    "    system_message=sys_message,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7044a90",
   "metadata": {},
   "source": [
    "# Code Documentation\n",
    "\n",
    "## Introduction\n",
    "This code is a Swift implementation of a model data handler for performing image classification using a pre-trained MobileNet model. It handles data preprocessing, runs inference on a given frame, and processes the inference results.\n",
    "\n",
    "## Classes and Structs\n",
    "\n",
    "### Inference\n",
    "- `Inference` is a struct that represents the result of invoking the `Interpreter`. It contains the confidence score and label of the predicted class.\n",
    "\n",
    "### FileInfo\n",
    "- `FileInfo` is a typealias for a tuple that represents information about a model file or labels file. It consists of a name and an extension.\n",
    "\n",
    "### MobileNet\n",
    "- `MobileNet` is an enum that provides information about the MobileNet model. It includes the model file name and extension.\n",
    "\n",
    "### ModelDataHandler\n",
    "- `ModelDataHandler` is a class that handles all data preprocessing and inference operations. It loads the model and labels files, runs inference on a given frame, and processes the results.\n",
    "\n",
    "#### Public Properties\n",
    "- `threadCount`: The current thread count used by the TensorFlow Lite Interpreter.\n",
    "- `resultCount`: The number of top results to return.\n",
    "\n",
    "#### Model Parameters\n",
    "- `batchSize`: The batch size used for inference.\n",
    "- `inputChannels`: The number of input channels in the model.\n",
    "- `inputWidth`: The width of the input image.\n",
    "- `inputHeight`: The height of the input image.\n",
    "\n",
    "#### Private Properties\n",
    "- `labels`: A list of labels from the labels file.\n",
    "- `interpreter`: The TensorFlow Lite `Interpreter` object for performing inference.\n",
    "- `alphaComponent`: Information about the alpha component in RGBA data.\n",
    "\n",
    "#### Initialization\n",
    "- `init?(modelFileInfo: FileInfo, threadCount: Int = 1)`: Initializes a new instance of `ModelDataHandler` with the specified model file info and thread count. It loads the model file and creates the `Interpreter` object.\n",
    "\n",
    "#### Public Methods\n",
    "- `runModel(onFrame pixelBuffer: CVPixelBuffer) -> [Inference]?`: Performs image preprocessing, runs inference on the given frame, and processes the inference results. It returns an array of `Inference` objects representing the top N results.\n",
    "\n",
    "#### Private Methods\n",
    "- `getTopN(results: [Float]) -> [Inference]`: Returns the top N inference results sorted in descending order.\n",
    "- `loadLabels(fileInfo: FileInfo)`: Loads the labels from the labels file and stores them in the `labels` property.\n",
    "- `rgbData"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd448047-b452-44de-86e4-cbf0144bcef3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e906f688-e361-4d64-8df0-c8a0fee10620",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
