{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "68e1c158",
      "metadata": {},
      "source": [
        "# Using Hugging Face With Skills\n",
        "\n",
        "In this notebook, we demonstrate using Hugging Face models for Skills using both SemanticMemory and text completions. \n",
        "\n",
        "SK supports downloading models from the Hugging Face that can perform the following tasks: text-generation, text2text-generation, summarization, and sentence-similarity. You can search for models by task at https://huggingface.co/models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "a77bdf89",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: semantic-kernel==0.3.15.dev0 in /home/chris/anaconda3/envs/semantic/lib/python3.11/site-packages (0.3.15.dev0)\n",
            "Requirement already satisfied: aiofiles<24.0.0,>=23.1.0 in /home/chris/anaconda3/envs/semantic/lib/python3.11/site-packages (from semantic-kernel==0.3.15.dev0) (23.2.1)\n",
            "Requirement already satisfied: motor<4.0.0,>=3.3.1 in /home/chris/anaconda3/envs/semantic/lib/python3.11/site-packages (from semantic-kernel==0.3.15.dev0) (3.3.2)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.24.2 in /home/chris/anaconda3/envs/semantic/lib/python3.11/site-packages (from semantic-kernel==0.3.15.dev0) (1.26.2)\n",
            "Requirement already satisfied: openai<0.29,>=0.27 in /home/chris/anaconda3/envs/semantic/lib/python3.11/site-packages (from semantic-kernel==0.3.15.dev0) (0.28.1)\n",
            "Requirement already satisfied: openapi_core<0.19.0,>=0.18.0 in /home/chris/anaconda3/envs/semantic/lib/python3.11/site-packages (from semantic-kernel==0.3.15.dev0) (0.18.2)\n",
            "Requirement already satisfied: prance<24.0.0.0,>=23.6.21.0 in /home/chris/anaconda3/envs/semantic/lib/python3.11/site-packages (from semantic-kernel==0.3.15.dev0) (23.6.21.0)\n",
            "Requirement already satisfied: pydantic<2 in /home/chris/anaconda3/envs/semantic/lib/python3.11/site-packages (from semantic-kernel==0.3.15.dev0) (1.10.13)\n",
            "Requirement already satisfied: python-dotenv==1.0.0 in /home/chris/anaconda3/envs/semantic/lib/python3.11/site-packages (from semantic-kernel==0.3.15.dev0) (1.0.0)\n",
            "Requirement already satisfied: regex<2024.0.0,>=2023.6.3 in /home/chris/anaconda3/envs/semantic/lib/python3.11/site-packages (from semantic-kernel==0.3.15.dev0) (2023.10.3)\n",
            "Requirement already satisfied: pymongo<5,>=4.5 in /home/chris/anaconda3/envs/semantic/lib/python3.11/site-packages (from motor<4.0.0,>=3.3.1->semantic-kernel==0.3.15.dev0) (4.6.0)\n",
            "Requirement already satisfied: requests>=2.20 in /home/chris/anaconda3/envs/semantic/lib/python3.11/site-packages (from openai<0.29,>=0.27->semantic-kernel==0.3.15.dev0) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /home/chris/anaconda3/envs/semantic/lib/python3.11/site-packages (from openai<0.29,>=0.27->semantic-kernel==0.3.15.dev0) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in /home/chris/anaconda3/envs/semantic/lib/python3.11/site-packages (from openai<0.29,>=0.27->semantic-kernel==0.3.15.dev0) (3.9.0)\n",
            "Requirement already satisfied: asgiref<4.0.0,>=3.6.0 in /home/chris/anaconda3/envs/semantic/lib/python3.11/site-packages (from openapi_core<0.19.0,>=0.18.0->semantic-kernel==0.3.15.dev0) (3.7.2)\n",
            "Requirement already satisfied: isodate in /home/chris/anaconda3/envs/semantic/lib/python3.11/site-packages (from openapi_core<0.19.0,>=0.18.0->semantic-kernel==0.3.15.dev0) (0.6.1)\n",
            "Requirement already satisfied: jsonschema<5.0.0,>=4.18.0 in /home/chris/.local/lib/python3.11/site-packages (from openapi_core<0.19.0,>=0.18.0->semantic-kernel==0.3.15.dev0) (4.19.2)\n",
            "Requirement already satisfied: jsonschema-spec<0.3.0,>=0.2.3 in /home/chris/anaconda3/envs/semantic/lib/python3.11/site-packages (from openapi_core<0.19.0,>=0.18.0->semantic-kernel==0.3.15.dev0) (0.2.4)\n",
            "Requirement already satisfied: more-itertools in /home/chris/anaconda3/envs/semantic/lib/python3.11/site-packages (from openapi_core<0.19.0,>=0.18.0->semantic-kernel==0.3.15.dev0) (10.1.0)\n",
            "Requirement already satisfied: openapi-schema-validator<0.7.0,>=0.6.0 in /home/chris/anaconda3/envs/semantic/lib/python3.11/site-packages (from openapi_core<0.19.0,>=0.18.0->semantic-kernel==0.3.15.dev0) (0.6.2)\n",
            "Requirement already satisfied: openapi-spec-validator<0.8.0,>=0.7.1 in /home/chris/anaconda3/envs/semantic/lib/python3.11/site-packages (from openapi_core<0.19.0,>=0.18.0->semantic-kernel==0.3.15.dev0) (0.7.1)\n",
            "Requirement already satisfied: parse in /home/chris/anaconda3/envs/semantic/lib/python3.11/site-packages (from openapi_core<0.19.0,>=0.18.0->semantic-kernel==0.3.15.dev0) (1.19.1)\n",
            "Requirement already satisfied: werkzeug in /home/chris/anaconda3/envs/semantic/lib/python3.11/site-packages (from openapi_core<0.19.0,>=0.18.0->semantic-kernel==0.3.15.dev0) (3.0.1)\n",
            "Requirement already satisfied: chardet>=3.0 in /home/chris/anaconda3/envs/semantic/lib/python3.11/site-packages (from prance<24.0.0.0,>=23.6.21.0->semantic-kernel==0.3.15.dev0) (5.2.0)\n",
            "Requirement already satisfied: ruamel.yaml>=0.17.10 in /home/chris/anaconda3/envs/semantic/lib/python3.11/site-packages (from prance<24.0.0.0,>=23.6.21.0->semantic-kernel==0.3.15.dev0) (0.18.5)\n",
            "Requirement already satisfied: six~=1.15 in /home/chris/anaconda3/envs/semantic/lib/python3.11/site-packages (from prance<24.0.0.0,>=23.6.21.0->semantic-kernel==0.3.15.dev0) (1.16.0)\n",
            "Requirement already satisfied: packaging>=21.3 in /home/chris/anaconda3/envs/semantic/lib/python3.11/site-packages (from prance<24.0.0.0,>=23.6.21.0->semantic-kernel==0.3.15.dev0) (23.2)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /home/chris/anaconda3/envs/semantic/lib/python3.11/site-packages (from pydantic<2->semantic-kernel==0.3.15.dev0) (4.8.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /home/chris/anaconda3/envs/semantic/lib/python3.11/site-packages (from jsonschema<5.0.0,>=4.18.0->openapi_core<0.19.0,>=0.18.0->semantic-kernel==0.3.15.dev0) (23.1.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/chris/.local/lib/python3.11/site-packages (from jsonschema<5.0.0,>=4.18.0->openapi_core<0.19.0,>=0.18.0->semantic-kernel==0.3.15.dev0) (2023.7.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /home/chris/.local/lib/python3.11/site-packages (from jsonschema<5.0.0,>=4.18.0->openapi_core<0.19.0,>=0.18.0->semantic-kernel==0.3.15.dev0) (0.30.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /home/chris/.local/lib/python3.11/site-packages (from jsonschema<5.0.0,>=4.18.0->openapi_core<0.19.0,>=0.18.0->semantic-kernel==0.3.15.dev0) (0.10.6)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /home/chris/anaconda3/envs/semantic/lib/python3.11/site-packages (from jsonschema-spec<0.3.0,>=0.2.3->openapi_core<0.19.0,>=0.18.0->semantic-kernel==0.3.15.dev0) (6.0.1)\n",
            "Requirement already satisfied: pathable<0.5.0,>=0.4.1 in /home/chris/anaconda3/envs/semantic/lib/python3.11/site-packages (from jsonschema-spec<0.3.0,>=0.2.3->openapi_core<0.19.0,>=0.18.0->semantic-kernel==0.3.15.dev0) (0.4.3)\n",
            "Requirement already satisfied: rfc3339-validator in /home/chris/anaconda3/envs/semantic/lib/python3.11/site-packages (from openapi-schema-validator<0.7.0,>=0.6.0->openapi_core<0.19.0,>=0.18.0->semantic-kernel==0.3.15.dev0) (0.1.4)\n",
            "Requirement already satisfied: jsonschema-path<0.4.0,>=0.3.1 in /home/chris/anaconda3/envs/semantic/lib/python3.11/site-packages (from openapi-spec-validator<0.8.0,>=0.7.1->openapi_core<0.19.0,>=0.18.0->semantic-kernel==0.3.15.dev0) (0.3.2)\n",
            "Requirement already satisfied: lazy-object-proxy<2.0.0,>=1.7.1 in /home/chris/anaconda3/envs/semantic/lib/python3.11/site-packages (from openapi-spec-validator<0.8.0,>=0.7.1->openapi_core<0.19.0,>=0.18.0->semantic-kernel==0.3.15.dev0) (1.9.0)\n",
            "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in /home/chris/anaconda3/envs/semantic/lib/python3.11/site-packages (from pymongo<5,>=4.5->motor<4.0.0,>=3.3.1->semantic-kernel==0.3.15.dev0) (2.4.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /home/chris/anaconda3/envs/semantic/lib/python3.11/site-packages (from requests>=2.20->openai<0.29,>=0.27->semantic-kernel==0.3.15.dev0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/chris/anaconda3/envs/semantic/lib/python3.11/site-packages (from requests>=2.20->openai<0.29,>=0.27->semantic-kernel==0.3.15.dev0) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/chris/anaconda3/envs/semantic/lib/python3.11/site-packages (from requests>=2.20->openai<0.29,>=0.27->semantic-kernel==0.3.15.dev0) (2.1.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/chris/anaconda3/envs/semantic/lib/python3.11/site-packages (from requests>=2.20->openai<0.29,>=0.27->semantic-kernel==0.3.15.dev0) (2023.11.17)\n",
            "Requirement already satisfied: ruamel.yaml.clib>=0.2.7 in /home/chris/anaconda3/envs/semantic/lib/python3.11/site-packages (from ruamel.yaml>=0.17.10->prance<24.0.0.0,>=23.6.21.0->semantic-kernel==0.3.15.dev0) (0.2.8)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /home/chris/anaconda3/envs/semantic/lib/python3.11/site-packages (from aiohttp->openai<0.29,>=0.27->semantic-kernel==0.3.15.dev0) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /home/chris/anaconda3/envs/semantic/lib/python3.11/site-packages (from aiohttp->openai<0.29,>=0.27->semantic-kernel==0.3.15.dev0) (1.9.3)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /home/chris/anaconda3/envs/semantic/lib/python3.11/site-packages (from aiohttp->openai<0.29,>=0.27->semantic-kernel==0.3.15.dev0) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /home/chris/anaconda3/envs/semantic/lib/python3.11/site-packages (from aiohttp->openai<0.29,>=0.27->semantic-kernel==0.3.15.dev0) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/chris/.local/lib/python3.11/site-packages (from werkzeug->openapi_core<0.19.0,>=0.18.0->semantic-kernel==0.3.15.dev0) (2.1.3)\n",
            "Collecting torch==2.0.0\n",
            "  Downloading torch-2.0.0-cp311-cp311-manylinux1_x86_64.whl (619.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0m00:02\u001b[0m\n",
            "\u001b[?25hCollecting filelock (from torch==2.0.0)\n",
            "  Using cached filelock-3.13.1-py3-none-any.whl.metadata (2.8 kB)\n",
            "Requirement already satisfied: typing-extensions in /home/chris/anaconda3/envs/semantic/lib/python3.11/site-packages (from torch==2.0.0) (4.8.0)\n",
            "Collecting sympy (from torch==2.0.0)\n",
            "  Using cached sympy-1.12-py3-none-any.whl (5.7 MB)\n",
            "Collecting networkx (from torch==2.0.0)\n",
            "  Using cached networkx-3.2.1-py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: jinja2 in /home/chris/.local/lib/python3.11/site-packages (from torch==2.0.0) (3.1.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch==2.0.0)\n",
            "  Using cached nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
            "Collecting nvidia-cuda-runtime-cu11==11.7.99 (from torch==2.0.0)\n",
            "  Using cached nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "Collecting nvidia-cuda-cupti-cu11==11.7.101 (from torch==2.0.0)\n",
            "  Using cached nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
            "Collecting nvidia-cudnn-cu11==8.5.0.96 (from torch==2.0.0)\n",
            "  Using cached nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "Collecting nvidia-cublas-cu11==11.10.3.66 (from torch==2.0.0)\n",
            "  Using cached nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "Collecting nvidia-cufft-cu11==10.9.0.58 (from torch==2.0.0)\n",
            "  Using cached nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n",
            "Collecting nvidia-curand-cu11==10.2.10.91 (from torch==2.0.0)\n",
            "  Using cached nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
            "Collecting nvidia-cusolver-cu11==11.4.0.1 (from torch==2.0.0)\n",
            "  Using cached nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
            "Collecting nvidia-cusparse-cu11==11.7.4.91 (from torch==2.0.0)\n",
            "  Using cached nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
            "Collecting nvidia-nccl-cu11==2.14.3 (from torch==2.0.0)\n",
            "  Using cached nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
            "Collecting nvidia-nvtx-cu11==11.7.91 (from torch==2.0.0)\n",
            "  Using cached nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
            "Collecting triton==2.0.0 (from torch==2.0.0)\n",
            "  Downloading triton-2.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools in /home/chris/anaconda3/envs/semantic/lib/python3.11/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0) (68.0.0)\n",
            "Requirement already satisfied: wheel in /home/chris/anaconda3/envs/semantic/lib/python3.11/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0) (0.41.2)\n",
            "Collecting cmake (from triton==2.0.0->torch==2.0.0)\n",
            "  Using cached cmake-3.27.7-py2.py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (6.7 kB)\n",
            "Collecting lit (from triton==2.0.0->torch==2.0.0)\n",
            "  Downloading lit-17.0.5.tar.gz (153 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.0/153.0 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
            "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
            "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
            "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /home/chris/.local/lib/python3.11/site-packages (from jinja2->torch==2.0.0) (2.1.3)\n",
            "Collecting mpmath>=0.19 (from sympy->torch==2.0.0)\n",
            "  Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "Using cached filelock-3.13.1-py3-none-any.whl (11 kB)\n",
            "Using cached networkx-3.2.1-py3-none-any.whl (1.6 MB)\n",
            "Using cached cmake-3.27.7-py2.py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (26.0 MB)\n",
            "Building wheels for collected packages: lit\n",
            "  Building wheel for lit (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for lit: filename=lit-17.0.5-py3-none-any.whl size=93256 sha256=7588db5ff4344db76e3202bbd82c1ec8e518d96a72e7f0f7b1f689b8eb24c4c7\n",
            "  Stored in directory: /home/chris/.cache/pip/wheels/a1/26/a4/40c6cd80874b94237593690352a2f657f5e4d7bddf6de4a6cd\n",
            "Successfully built lit\n",
            "Installing collected packages: mpmath, lit, cmake, sympy, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, networkx, filelock, nvidia-cusolver-cu11, nvidia-cudnn-cu11, triton, torch\n",
            "Successfully installed cmake-3.27.7 filelock-3.13.1 lit-17.0.5 mpmath-1.3.0 networkx-3.2.1 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 sympy-1.12 torch-2.0.0 triton-2.0.0\n",
            "\u001b[31mERROR: Ignored the following yanked versions: 4.14.0, 4.25.0\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement transformers==^4.28.1 (from versions: 0.1, 2.0.0, 2.1.0, 2.1.1, 2.2.0, 2.2.1, 2.2.2, 2.3.0, 2.4.0, 2.4.1, 2.5.0, 2.5.1, 2.6.0, 2.7.0, 2.8.0, 2.9.0, 2.9.1, 2.10.0, 2.11.0, 3.0.0, 3.0.1, 3.0.2, 3.1.0, 3.2.0, 3.3.0, 3.3.1, 3.4.0, 3.5.0, 3.5.1, 4.0.0rc1, 4.0.0, 4.0.1, 4.1.0, 4.1.1, 4.2.0, 4.2.1, 4.2.2, 4.3.0rc1, 4.3.0, 4.3.1, 4.3.2, 4.3.3, 4.4.0, 4.4.1, 4.4.2, 4.5.0, 4.5.1, 4.6.0, 4.6.1, 4.7.0, 4.8.0, 4.8.1, 4.8.2, 4.9.0, 4.9.1, 4.9.2, 4.10.0, 4.10.1, 4.10.2, 4.10.3, 4.11.0, 4.11.1, 4.11.2, 4.11.3, 4.12.0, 4.12.1, 4.12.2, 4.12.3, 4.12.4, 4.12.5, 4.13.0, 4.14.1, 4.15.0, 4.16.0, 4.16.1, 4.16.2, 4.17.0, 4.18.0, 4.19.0, 4.19.1, 4.19.2, 4.19.3, 4.19.4, 4.20.0, 4.20.1, 4.21.0, 4.21.1, 4.21.2, 4.21.3, 4.22.0, 4.22.1, 4.22.2, 4.23.0, 4.23.1, 4.24.0, 4.25.1, 4.26.0, 4.26.1, 4.27.0, 4.27.1, 4.27.2, 4.27.3, 4.27.4, 4.28.0, 4.28.1, 4.29.0, 4.29.1, 4.29.2, 4.30.0, 4.30.1, 4.30.2, 4.31.0, 4.32.0, 4.32.1, 4.33.0, 4.33.1, 4.33.2, 4.33.3, 4.34.0, 4.34.1, 4.35.0, 4.35.1, 4.35.2)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for transformers==^4.28.1\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Ignored the following yanked versions: 0.2.6\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement sentence-transformers==^2.2.2 (from versions: 0.1.0, 0.2.0, 0.2.1, 0.2.2, 0.2.3, 0.2.4, 0.2.4.1, 0.2.5, 0.2.5.1, 0.2.6.1, 0.2.6.2, 0.3.0, 0.3.1, 0.3.2, 0.3.3, 0.3.4, 0.3.5, 0.3.5.1, 0.3.6, 0.3.7, 0.3.7.1, 0.3.7.2, 0.3.8, 0.3.9, 0.4.0, 0.4.1, 0.4.1.1, 0.4.1.2, 1.0.0, 1.0.1, 1.0.2, 1.0.3, 1.0.4, 1.1.0, 1.1.1, 1.2.0, 1.2.1, 2.0.0, 2.1.0, 2.2.0, 2.2.1, 2.2.2)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for sentence-transformers==^2.2.2\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!python -m pip install semantic-kernel==0.3.15.dev0\n",
        "\n",
        "# Note that additional dependencies are required for the Hugging Face connectors:\n",
        "!python -m pip install torch==2.0.0\n",
        "!python -m pip install transformers==^4.28.1\n",
        "!python -m pip install sentence-transformers==^2.2.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "508ad44f",
      "metadata": {},
      "outputs": [],
      "source": [
        "import semantic_kernel as sk\n",
        "import semantic_kernel.connectors.ai.hugging_face as sk_hf"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "d8ddffc1",
      "metadata": {},
      "source": [
        "First, we will create a kernel and add both text completion and embedding services. \n",
        "\n",
        "For text completion, we are choosing GPT2. This is a text-generation model. (Note: text-generation will repeat the input in the output, text2text-generation will not.)\n",
        "For embeddings, we are using sentence-transformers/all-MiniLM-L6-v2. Vectors generated for this model are of length 384 (compared to a length of 1536 from OpenAI ADA).\n",
        "\n",
        "The following step may take a few minutes when run for the first time as the models will be downloaded to your local machine."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "8f8dcbc6",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ".gitattributes: 100%|██████████| 1.18k/1.18k [00:00<00:00, 7.04MB/s]\n",
            "1_Pooling/config.json: 100%|██████████| 190/190 [00:00<00:00, 602kB/s]\n",
            "README.md: 100%|██████████| 10.6k/10.6k [00:00<00:00, 48.3MB/s]\n",
            "config.json: 100%|██████████| 612/612 [00:00<00:00, 4.24MB/s]\n",
            "config_sentence_transformers.json: 100%|██████████| 116/116 [00:00<00:00, 763kB/s]\n",
            "data_config.json: 100%|██████████| 39.3k/39.3k [00:00<00:00, 13.3MB/s]\n",
            "pytorch_model.bin: 100%|██████████| 90.9M/90.9M [00:07<00:00, 11.5MB/s]\n",
            "sentence_bert_config.json: 100%|██████████| 53.0/53.0 [00:00<00:00, 286kB/s]\n",
            "special_tokens_map.json: 100%|██████████| 112/112 [00:00<00:00, 501kB/s]\n",
            "tokenizer.json: 100%|██████████| 466k/466k [00:00<00:00, 6.88MB/s]\n",
            "tokenizer_config.json: 100%|██████████| 350/350 [00:00<00:00, 1.90MB/s]\n",
            "train_script.py: 100%|██████████| 13.2k/13.2k [00:00<00:00, 42.4MB/s]\n",
            "vocab.txt: 100%|██████████| 232k/232k [00:00<00:00, 14.3MB/s]\n",
            "modules.json: 100%|██████████| 349/349 [00:00<00:00, 1.50MB/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'recall': <semantic_kernel.orchestration.sk_function.SKFunction at 0x7ff2f1c77f10>,\n",
              " 'save': <semantic_kernel.orchestration.sk_function.SKFunction at 0x7ff2f1c9c1d0>}"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "kernel = sk.Kernel()\n",
        "\n",
        "# Configure LLM service\n",
        "kernel.add_text_completion_service(\n",
        "    \"gpt2\", sk_hf.HuggingFaceTextCompletion(\"gpt2\", task=\"text-generation\")\n",
        ")\n",
        "kernel.add_text_embedding_generation_service(\n",
        "    \"sentence-transformers/all-MiniLM-L6-v2\",\n",
        "    sk_hf.HuggingFaceTextEmbedding(\"sentence-transformers/all-MiniLM-L6-v2\"),\n",
        ")\n",
        "kernel.register_memory_store(memory_store=sk.memory.VolatileMemoryStore())\n",
        "kernel.import_skill(sk.core_skills.TextMemorySkill())"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "2a7e7ca4",
      "metadata": {},
      "source": [
        "### Add Memories and Define a skill to use them\n",
        "\n",
        "Most models available on huggingface.co are not as powerful as OpenAI GPT-3+. Your skills will likely need to be simpler to accommodate this."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "d096504c",
      "metadata": {},
      "outputs": [],
      "source": [
        "await kernel.memory.save_information_async(\n",
        "    \"animal-facts\", id=\"info1\", text=\"Sharks are fish.\"\n",
        ")\n",
        "await kernel.memory.save_information_async(\n",
        "    \"animal-facts\", id=\"info2\", text=\"Whales are mammals.\"\n",
        ")\n",
        "await kernel.memory.save_information_async(\n",
        "    \"animal-facts\", id=\"info3\", text=\"Penguins are birds.\"\n",
        ")\n",
        "await kernel.memory.save_information_async(\n",
        "    \"animal-facts\", id=\"info4\", text=\"Dolphins are mammals.\"\n",
        ")\n",
        "await kernel.memory.save_information_async(\n",
        "    \"animal-facts\", id=\"info5\", text=\"Flies are insects.\"\n",
        ")\n",
        "\n",
        "# Define semantic function using SK prompt template language\n",
        "my_prompt = \"\"\"I know these animal facts: {{recall $query1}} {{recall $query2}} {{recall $query3}} and \"\"\"\n",
        "\n",
        "# Create the semantic function\n",
        "my_function = kernel.create_semantic_function(\n",
        "    my_prompt, max_tokens=45, temperature=0.5, top_p=0.5\n",
        ")\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "2calf857",
      "metadata": {},
      "source": [
        "Let's now see what the completion looks like! Remember, \"gpt2\" is nowhere near as large as ChatGPT, so expect a much simpler answer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "628c843e",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/chris/anaconda3/envs/semantic/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:381: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.5` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
            "  warnings.warn(\n",
            "/home/chris/anaconda3/envs/semantic/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:386: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.5` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "gpt2 completed prompt with: 'I know these animal facts: Dolphins are mammals. Flies are insects. Penguins are birds. and  I'm not even sure if they're all mammals. But I do know that the Dolphins are mammals. And I'm not even sure if they're all mammals. But I do know that the Dolphins are mammals. And'\n"
          ]
        }
      ],
      "source": [
        "context = kernel.create_new_context()\n",
        "context[sk.core_skills.TextMemorySkill.COLLECTION_PARAM] = \"animal-facts\"\n",
        "context[sk.core_skills.TextMemorySkill.RELEVANCE_PARAM] = 0.3\n",
        "\n",
        "context[\"query1\"] = \"animal that swims\"\n",
        "context[\"query2\"] = \"animal that flies\"\n",
        "context[\"query3\"] = \"penguins are?\"\n",
        "output = await kernel.run_async(my_function, input_vars=context.variables)\n",
        "\n",
        "output = str(output).strip()\n",
        "\n",
        "\n",
        "query_result1 = await kernel.memory.search_async(\n",
        "    \"animal-facts\", context[\"query1\"], limit=1, min_relevance_score=0.3\n",
        ")\n",
        "query_result2 = await kernel.memory.search_async(\n",
        "    \"animal-facts\", context[\"query2\"], limit=1, min_relevance_score=0.3\n",
        ")\n",
        "query_result3 = await kernel.memory.search_async(\n",
        "    \"animal-facts\", context[\"query3\"], limit=1, min_relevance_score=0.3\n",
        ")\n",
        "\n",
        "print(f\"gpt2 completed prompt with: '{output}'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
