{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# import openai\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../..\")\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "_ = load_dotenv(find_dotenv())  # read local .env file\n",
    "GOOGLE_STUDIO_API_KEY = os.getenv(\"GOOGLE_STUDIO_API_KEY\")\n",
    "GOOGLE_OAUTH_API_KEY = os.getenv(\"GOOGLE_OAUTH_API_KEY\")\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_39991/3975915949.py:4: ResourceWarning: unclosed <socket.socket fd=80, family=2, type=1, proto=6, laddr=('127.0.0.1', 39522), raddr=('127.0.0.1', 8080)>\n",
      "  client = weaviate.connect_to_local(headers=headers)\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    }
   ],
   "source": [
    "import weaviate\n",
    "\n",
    "headers = {\"X-OpenAI-Api-Key\": OPENAI_API_KEY}\n",
    "client = weaviate.connect_to_local(headers=headers)\n",
    "# client = weaviate.connect_to_local()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert client.is_live()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"hostname\": \"http://[::]:8080\",\n",
      "  \"modules\": {\n",
      "    \"generative-cohere\": {\n",
      "      \"documentationHref\": \"https://docs.cohere.com/reference/chat\",\n",
      "      \"name\": \"Generative Search - Cohere\"\n",
      "    },\n",
      "    \"generative-openai\": {\n",
      "      \"documentationHref\": \"https://platform.openai.com/docs/api-reference/completions\",\n",
      "      \"name\": \"Generative Search - OpenAI\"\n",
      "    },\n",
      "    \"multi2vec-clip\": {\n",
      "      \"clip_model\": {\n",
      "        \"_commit_hash\": null,\n",
      "        \"_name_or_path\": \"/root/.cache/torch/sentence_transformers/sentence-transformers_clip-ViT-B-32/0_CLIPModel\",\n",
      "        \"add_cross_attention\": false,\n",
      "        \"architectures\": [\n",
      "          \"CLIPModel\"\n",
      "        ],\n",
      "        \"bad_words_ids\": null,\n",
      "        \"begin_suppress_tokens\": null,\n",
      "        \"bos_token_id\": null,\n",
      "        \"chunk_size_feed_forward\": 0,\n",
      "        \"cross_attention_hidden_size\": null,\n",
      "        \"decoder_start_token_id\": null,\n",
      "        \"diversity_penalty\": 0,\n",
      "        \"do_sample\": false,\n",
      "        \"early_stopping\": false,\n",
      "        \"encoder_no_repeat_ngram_size\": 0,\n",
      "        \"eos_token_id\": null,\n",
      "        \"exponential_decay_length_penalty\": null,\n",
      "        \"finetuning_task\": null,\n",
      "        \"forced_bos_token_id\": null,\n",
      "        \"forced_eos_token_id\": null,\n",
      "        \"id2label\": {\n",
      "          \"0\": \"LABEL_0\",\n",
      "          \"1\": \"LABEL_1\"\n",
      "        },\n",
      "        \"initializer_factor\": 1,\n",
      "        \"is_decoder\": false,\n",
      "        \"is_encoder_decoder\": false,\n",
      "        \"label2id\": {\n",
      "          \"LABEL_0\": 0,\n",
      "          \"LABEL_1\": 1\n",
      "        },\n",
      "        \"length_penalty\": 1,\n",
      "        \"logit_scale_init_value\": 2.6592,\n",
      "        \"max_length\": 20,\n",
      "        \"min_length\": 0,\n",
      "        \"model_type\": \"clip\",\n",
      "        \"no_repeat_ngram_size\": 0,\n",
      "        \"num_beam_groups\": 1,\n",
      "        \"num_beams\": 1,\n",
      "        \"num_return_sequences\": 1,\n",
      "        \"output_attentions\": false,\n",
      "        \"output_hidden_states\": false,\n",
      "        \"output_scores\": false,\n",
      "        \"pad_token_id\": null,\n",
      "        \"prefix\": null,\n",
      "        \"problem_type\": null,\n",
      "        \"projection_dim\": 512,\n",
      "        \"pruned_heads\": {},\n",
      "        \"remove_invalid_values\": false,\n",
      "        \"repetition_penalty\": 1,\n",
      "        \"return_dict\": true,\n",
      "        \"return_dict_in_generate\": false,\n",
      "        \"sep_token_id\": null,\n",
      "        \"suppress_tokens\": null,\n",
      "        \"task_specific_params\": null,\n",
      "        \"temperature\": 1,\n",
      "        \"text_config\": {\n",
      "          \"_name_or_path\": \"\",\n",
      "          \"add_cross_attention\": false,\n",
      "          \"architectures\": null,\n",
      "          \"attention_dropout\": 0,\n",
      "          \"bad_words_ids\": null,\n",
      "          \"begin_suppress_tokens\": null,\n",
      "          \"bos_token_id\": 0,\n",
      "          \"chunk_size_feed_forward\": 0,\n",
      "          \"cross_attention_hidden_size\": null,\n",
      "          \"decoder_start_token_id\": null,\n",
      "          \"diversity_penalty\": 0,\n",
      "          \"do_sample\": false,\n",
      "          \"dropout\": 0,\n",
      "          \"early_stopping\": false,\n",
      "          \"encoder_no_repeat_ngram_size\": 0,\n",
      "          \"eos_token_id\": 2,\n",
      "          \"exponential_decay_length_penalty\": null,\n",
      "          \"finetuning_task\": null,\n",
      "          \"forced_bos_token_id\": null,\n",
      "          \"forced_eos_token_id\": null,\n",
      "          \"gradient_checkpointing\": false,\n",
      "          \"hidden_act\": \"quick_gelu\",\n",
      "          \"hidden_size\": 512,\n",
      "          \"id2label\": {\n",
      "            \"0\": \"LABEL_0\",\n",
      "            \"1\": \"LABEL_1\"\n",
      "          },\n",
      "          \"initializer_factor\": 1,\n",
      "          \"initializer_range\": 0.02,\n",
      "          \"intermediate_size\": 2048,\n",
      "          \"is_decoder\": false,\n",
      "          \"is_encoder_decoder\": false,\n",
      "          \"label2id\": {\n",
      "            \"LABEL_0\": 0,\n",
      "            \"LABEL_1\": 1\n",
      "          },\n",
      "          \"layer_norm_eps\": 1e-05,\n",
      "          \"length_penalty\": 1,\n",
      "          \"max_length\": 20,\n",
      "          \"max_position_embeddings\": 77,\n",
      "          \"min_length\": 0,\n",
      "          \"model_type\": \"clip_text_model\",\n",
      "          \"no_repeat_ngram_size\": 0,\n",
      "          \"num_attention_heads\": 8,\n",
      "          \"num_beam_groups\": 1,\n",
      "          \"num_beams\": 1,\n",
      "          \"num_hidden_layers\": 12,\n",
      "          \"num_return_sequences\": 1,\n",
      "          \"output_attentions\": false,\n",
      "          \"output_hidden_states\": false,\n",
      "          \"output_scores\": false,\n",
      "          \"pad_token_id\": 1,\n",
      "          \"prefix\": null,\n",
      "          \"problem_type\": null,\n",
      "          \"projection_dim\": 512,\n",
      "          \"pruned_heads\": {},\n",
      "          \"remove_invalid_values\": false,\n",
      "          \"repetition_penalty\": 1,\n",
      "          \"return_dict\": true,\n",
      "          \"return_dict_in_generate\": false,\n",
      "          \"sep_token_id\": null,\n",
      "          \"suppress_tokens\": null,\n",
      "          \"task_specific_params\": null,\n",
      "          \"temperature\": 1,\n",
      "          \"tf_legacy_loss\": false,\n",
      "          \"tie_encoder_decoder\": false,\n",
      "          \"tie_word_embeddings\": true,\n",
      "          \"tokenizer_class\": null,\n",
      "          \"top_k\": 50,\n",
      "          \"top_p\": 1,\n",
      "          \"torch_dtype\": null,\n",
      "          \"torchscript\": false,\n",
      "          \"transformers_version\": \"4.30.2\",\n",
      "          \"typical_p\": 1,\n",
      "          \"use_bfloat16\": false,\n",
      "          \"vocab_size\": 49408\n",
      "        },\n",
      "        \"tf_legacy_loss\": false,\n",
      "        \"tie_encoder_decoder\": false,\n",
      "        \"tie_word_embeddings\": true,\n",
      "        \"tokenizer_class\": null,\n",
      "        \"top_k\": 50,\n",
      "        \"top_p\": 1,\n",
      "        \"torch_dtype\": \"torch.float32\",\n",
      "        \"torchscript\": false,\n",
      "        \"transformers_version\": null,\n",
      "        \"typical_p\": 1,\n",
      "        \"use_bfloat16\": false,\n",
      "        \"vision_config\": {\n",
      "          \"_name_or_path\": \"\",\n",
      "          \"add_cross_attention\": false,\n",
      "          \"architectures\": null,\n",
      "          \"attention_dropout\": 0,\n",
      "          \"bad_words_ids\": null,\n",
      "          \"begin_suppress_tokens\": null,\n",
      "          \"bos_token_id\": null,\n",
      "          \"chunk_size_feed_forward\": 0,\n",
      "          \"cross_attention_hidden_size\": null,\n",
      "          \"decoder_start_token_id\": null,\n",
      "          \"diversity_penalty\": 0,\n",
      "          \"do_sample\": false,\n",
      "          \"dropout\": 0,\n",
      "          \"early_stopping\": false,\n",
      "          \"encoder_no_repeat_ngram_size\": 0,\n",
      "          \"eos_token_id\": null,\n",
      "          \"exponential_decay_length_penalty\": null,\n",
      "          \"finetuning_task\": null,\n",
      "          \"forced_bos_token_id\": null,\n",
      "          \"forced_eos_token_id\": null,\n",
      "          \"gradient_checkpointing\": false,\n",
      "          \"hidden_act\": \"quick_gelu\",\n",
      "          \"hidden_size\": 768,\n",
      "          \"id2label\": {\n",
      "            \"0\": \"LABEL_0\",\n",
      "            \"1\": \"LABEL_1\"\n",
      "          },\n",
      "          \"image_size\": 224,\n",
      "          \"initializer_factor\": 1,\n",
      "          \"initializer_range\": 0.02,\n",
      "          \"intermediate_size\": 3072,\n",
      "          \"is_decoder\": false,\n",
      "          \"is_encoder_decoder\": false,\n",
      "          \"label2id\": {\n",
      "            \"LABEL_0\": 0,\n",
      "            \"LABEL_1\": 1\n",
      "          },\n",
      "          \"layer_norm_eps\": 1e-05,\n",
      "          \"length_penalty\": 1,\n",
      "          \"max_length\": 20,\n",
      "          \"min_length\": 0,\n",
      "          \"model_type\": \"clip_vision_model\",\n",
      "          \"no_repeat_ngram_size\": 0,\n",
      "          \"num_attention_heads\": 12,\n",
      "          \"num_beam_groups\": 1,\n",
      "          \"num_beams\": 1,\n",
      "          \"num_channels\": 3,\n",
      "          \"num_hidden_layers\": 12,\n",
      "          \"num_return_sequences\": 1,\n",
      "          \"output_attentions\": false,\n",
      "          \"output_hidden_states\": false,\n",
      "          \"output_scores\": false,\n",
      "          \"pad_token_id\": null,\n",
      "          \"patch_size\": 32,\n",
      "          \"prefix\": null,\n",
      "          \"problem_type\": null,\n",
      "          \"projection_dim\": 512,\n",
      "          \"pruned_heads\": {},\n",
      "          \"remove_invalid_values\": false,\n",
      "          \"repetition_penalty\": 1,\n",
      "          \"return_dict\": true,\n",
      "          \"return_dict_in_generate\": false,\n",
      "          \"sep_token_id\": null,\n",
      "          \"suppress_tokens\": null,\n",
      "          \"task_specific_params\": null,\n",
      "          \"temperature\": 1,\n",
      "          \"tf_legacy_loss\": false,\n",
      "          \"tie_encoder_decoder\": false,\n",
      "          \"tie_word_embeddings\": true,\n",
      "          \"tokenizer_class\": null,\n",
      "          \"top_k\": 50,\n",
      "          \"top_p\": 1,\n",
      "          \"torch_dtype\": null,\n",
      "          \"torchscript\": false,\n",
      "          \"transformers_version\": \"4.30.2\",\n",
      "          \"typical_p\": 1,\n",
      "          \"use_bfloat16\": false\n",
      "        }\n",
      "      },\n",
      "      \"text_model\": {\n",
      "        \"_name_or_path\": \"./models/text\",\n",
      "        \"activation\": \"gelu\",\n",
      "        \"add_cross_attention\": false,\n",
      "        \"architectures\": [\n",
      "          \"DistilBertModel\"\n",
      "        ],\n",
      "        \"attention_dropout\": 0.1,\n",
      "        \"bad_words_ids\": null,\n",
      "        \"begin_suppress_tokens\": null,\n",
      "        \"bos_token_id\": null,\n",
      "        \"chunk_size_feed_forward\": 0,\n",
      "        \"cross_attention_hidden_size\": null,\n",
      "        \"decoder_start_token_id\": null,\n",
      "        \"dim\": 768,\n",
      "        \"diversity_penalty\": 0,\n",
      "        \"do_sample\": false,\n",
      "        \"dropout\": 0.1,\n",
      "        \"early_stopping\": false,\n",
      "        \"encoder_no_repeat_ngram_size\": 0,\n",
      "        \"eos_token_id\": null,\n",
      "        \"exponential_decay_length_penalty\": null,\n",
      "        \"finetuning_task\": null,\n",
      "        \"forced_bos_token_id\": null,\n",
      "        \"forced_eos_token_id\": null,\n",
      "        \"hidden_dim\": 3072,\n",
      "        \"id2label\": {\n",
      "          \"0\": \"LABEL_0\",\n",
      "          \"1\": \"LABEL_1\"\n",
      "        },\n",
      "        \"initializer_range\": 0.02,\n",
      "        \"is_decoder\": false,\n",
      "        \"is_encoder_decoder\": false,\n",
      "        \"label2id\": {\n",
      "          \"LABEL_0\": 0,\n",
      "          \"LABEL_1\": 1\n",
      "        },\n",
      "        \"length_penalty\": 1,\n",
      "        \"max_length\": 20,\n",
      "        \"max_position_embeddings\": 512,\n",
      "        \"min_length\": 0,\n",
      "        \"model_type\": \"distilbert\",\n",
      "        \"n_heads\": 12,\n",
      "        \"n_layers\": 6,\n",
      "        \"no_repeat_ngram_size\": 0,\n",
      "        \"num_beam_groups\": 1,\n",
      "        \"num_beams\": 1,\n",
      "        \"num_return_sequences\": 1,\n",
      "        \"output_attentions\": false,\n",
      "        \"output_hidden_states\": false,\n",
      "        \"output_past\": true,\n",
      "        \"output_scores\": false,\n",
      "        \"pad_token_id\": 0,\n",
      "        \"prefix\": null,\n",
      "        \"problem_type\": null,\n",
      "        \"pruned_heads\": {},\n",
      "        \"qa_dropout\": 0.1,\n",
      "        \"remove_invalid_values\": false,\n",
      "        \"repetition_penalty\": 1,\n",
      "        \"return_dict\": true,\n",
      "        \"return_dict_in_generate\": false,\n",
      "        \"sep_token_id\": null,\n",
      "        \"seq_classif_dropout\": 0.2,\n",
      "        \"sinusoidal_pos_embds\": false,\n",
      "        \"suppress_tokens\": null,\n",
      "        \"task_specific_params\": null,\n",
      "        \"temperature\": 1,\n",
      "        \"tf_legacy_loss\": false,\n",
      "        \"tie_encoder_decoder\": false,\n",
      "        \"tie_weights_\": true,\n",
      "        \"tie_word_embeddings\": true,\n",
      "        \"tokenizer_class\": null,\n",
      "        \"top_k\": 50,\n",
      "        \"top_p\": 1,\n",
      "        \"torch_dtype\": \"float32\",\n",
      "        \"torchscript\": false,\n",
      "        \"transformers_version\": \"4.30.2\",\n",
      "        \"typical_p\": 1,\n",
      "        \"use_bfloat16\": false,\n",
      "        \"vocab_size\": 119547\n",
      "      }\n",
      "    }\n",
      "  },\n",
      "  \"version\": \"1.25.1\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "metainfo = client.get_meta()\n",
    "print(json.dumps(metainfo, indent=2))  # Print the meta information in a readable format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# client.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<weaviate.collections.collection.Collection at 0x7f9a34a10e90>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import weaviate.classes.config as wc\n",
    "\n",
    "client.collections.create(\n",
    "    name=\"MovieMM\",  # The name of the collection ('MM' for multimodal)\n",
    "    properties=[\n",
    "        wc.Property(name=\"title\", data_type=wc.DataType.TEXT),\n",
    "        wc.Property(name=\"overview\", data_type=wc.DataType.TEXT),\n",
    "        wc.Property(name=\"vote_average\", data_type=wc.DataType.NUMBER),\n",
    "        wc.Property(name=\"genre_ids\", data_type=wc.DataType.INT_ARRAY),\n",
    "        wc.Property(name=\"release_date\", data_type=wc.DataType.DATE),\n",
    "        wc.Property(name=\"tmdb_id\", data_type=wc.DataType.INT),\n",
    "        wc.Property(name=\"poster\", data_type=wc.DataType.BLOB),\n",
    "    ],\n",
    "    # Define & configure the vectorizer module\n",
    "    vectorizer_config=wc.Configure.Vectorizer.multi2vec_clip(\n",
    "        image_fields=[\n",
    "            wc.Multi2VecField(name=\"poster\", weight=0.9)\n",
    "        ],  # 90% of the vector is from the poster\n",
    "        text_fields=[\n",
    "            wc.Multi2VecField(name=\"title\", weight=0.1)\n",
    "        ],  # 10% of the vector is from the title\n",
    "    ),\n",
    "    # Define the generative module\n",
    "    generative_config=wc.Configure.Generative.openai(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Movie Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "680it [03:43,  3.05it/s]\n"
     ]
    }
   ],
   "source": [
    "import weaviate\n",
    "import pandas as pd\n",
    "import requests\n",
    "from datetime import datetime, timezone\n",
    "import json\n",
    "from weaviate.util import generate_uuid5\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "import base64\n",
    "\n",
    "# Instantiate your client (not shown). e.g.:\n",
    "# client = weaviate.connect_to_local()\n",
    "\n",
    "data_url = \"https://raw.githubusercontent.com/weaviate-tutorials/edu-datasets/main/movies_data_1990_2024.json\"\n",
    "resp = requests.get(data_url)\n",
    "df = pd.DataFrame(resp.json())\n",
    "\n",
    "# Create a directory for the images\n",
    "img_dir = Path(\"scratch/imgs\")\n",
    "img_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Download images\n",
    "posters_url = \"https://raw.githubusercontent.com/weaviate-tutorials/edu-datasets/main/movies_data_1990_2024_posters.zip\"\n",
    "posters_path = img_dir / \"movies_data_1990_2024_posters.zip\"\n",
    "posters_path.write_bytes(requests.get(posters_url).content)\n",
    "\n",
    "# Unzip the images\n",
    "with zipfile.ZipFile(posters_path, \"r\") as zip_ref:\n",
    "    zip_ref.extractall(img_dir)\n",
    "\n",
    "# Get the collection\n",
    "movies = client.collections.get(\"MovieMM\")\n",
    "\n",
    "# Enter context manager\n",
    "with movies.batch.fixed_size(50) as batch:\n",
    "    # Loop through the data\n",
    "    for i, movie in tqdm(df.iterrows()):\n",
    "        # Convert data types\n",
    "        # Convert a JSON date to `datetime` and add time zone information\n",
    "        release_date = datetime.strptime(movie[\"release_date\"], \"%Y-%m-%d\").replace(\n",
    "            tzinfo=timezone.utc\n",
    "        )\n",
    "        # Convert a JSON array to a list of integers\n",
    "        genre_ids = json.loads(movie[\"genre_ids\"])\n",
    "        # Convert image to base64\n",
    "        img_path = img_dir / f\"{movie['id']}_poster.jpg\"\n",
    "        with open(img_path, \"rb\") as file:\n",
    "            poster_b64 = base64.b64encode(file.read()).decode(\"utf-8\")\n",
    "\n",
    "        # Build the object payload\n",
    "        movie_obj = {\n",
    "            \"title\": movie[\"title\"],\n",
    "            \"overview\": movie[\"overview\"],\n",
    "            \"vote_average\": movie[\"vote_average\"],\n",
    "            \"genre_ids\": genre_ids,\n",
    "            \"release_date\": release_date,\n",
    "            \"tmdb_id\": movie[\"id\"],\n",
    "            \"poster\": poster_b64,\n",
    "        }\n",
    "\n",
    "        # Add object to batch queue\n",
    "        batch.add_object(\n",
    "            properties=movie_obj,\n",
    "            uuid=generate_uuid5(movie[\"id\"]),\n",
    "            # references=reference_obj  # You can add references here\n",
    "        )\n",
    "        # Batcher automatically sends batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to import 37 objects\n",
      "e.g. Failed to import object with error: send POST request: Post \"http://multi2vec-clip:8080/vectorize\": context deadline exceeded (Client.Timeout exceeded while awaiting headers)\n",
      "e.g. Failed to import object with error: send POST request: Post \"http://multi2vec-clip:8080/vectorize\": context deadline exceeded (Client.Timeout exceeded while awaiting headers)\n",
      "e.g. Failed to import object with error: send POST request: Post \"http://multi2vec-clip:8080/vectorize\": context deadline exceeded (Client.Timeout exceeded while awaiting headers)\n",
      "e.g. Failed to import object with error: send POST request: Post \"http://multi2vec-clip:8080/vectorize\": context deadline exceeded (Client.Timeout exceeded while awaiting headers)\n",
      "e.g. Failed to import object with error: send POST request: Post \"http://multi2vec-clip:8080/vectorize\": context deadline exceeded (Client.Timeout exceeded while awaiting headers)\n",
      "e.g. Failed to import object with error: send POST request: Post \"http://multi2vec-clip:8080/vectorize\": context deadline exceeded (Client.Timeout exceeded while awaiting headers)\n",
      "e.g. Failed to import object with error: send POST request: Post \"http://multi2vec-clip:8080/vectorize\": context deadline exceeded (Client.Timeout exceeded while awaiting headers)\n",
      "e.g. Failed to import object with error: send POST request: Post \"http://multi2vec-clip:8080/vectorize\": context deadline exceeded (Client.Timeout exceeded while awaiting headers)\n",
      "e.g. Failed to import object with error: send POST request: Post \"http://multi2vec-clip:8080/vectorize\": context deadline exceeded (Client.Timeout exceeded while awaiting headers)\n",
      "e.g. Failed to import object with error: send POST request: Post \"http://multi2vec-clip:8080/vectorize\": context deadline exceeded (Client.Timeout exceeded while awaiting headers)\n",
      "e.g. Failed to import object with error: send POST request: Post \"http://multi2vec-clip:8080/vectorize\": context deadline exceeded (Client.Timeout exceeded while awaiting headers)\n",
      "e.g. Failed to import object with error: send POST request: Post \"http://multi2vec-clip:8080/vectorize\": context deadline exceeded (Client.Timeout exceeded while awaiting headers)\n",
      "e.g. Failed to import object with error: send POST request: Post \"http://multi2vec-clip:8080/vectorize\": context deadline exceeded (Client.Timeout exceeded while awaiting headers)\n",
      "e.g. Failed to import object with error: send POST request: Post \"http://multi2vec-clip:8080/vectorize\": context deadline exceeded (Client.Timeout exceeded while awaiting headers)\n",
      "e.g. Failed to import object with error: send POST request: Post \"http://multi2vec-clip:8080/vectorize\": context deadline exceeded (Client.Timeout exceeded while awaiting headers)\n",
      "e.g. Failed to import object with error: send POST request: Post \"http://multi2vec-clip:8080/vectorize\": context deadline exceeded (Client.Timeout exceeded while awaiting headers)\n",
      "e.g. Failed to import object with error: send POST request: Post \"http://multi2vec-clip:8080/vectorize\": context deadline exceeded (Client.Timeout exceeded while awaiting headers)\n",
      "e.g. Failed to import object with error: send POST request: Post \"http://multi2vec-clip:8080/vectorize\": context deadline exceeded (Client.Timeout exceeded while awaiting headers)\n",
      "e.g. Failed to import object with error: send POST request: Post \"http://multi2vec-clip:8080/vectorize\": context deadline exceeded (Client.Timeout exceeded while awaiting headers)\n",
      "e.g. Failed to import object with error: send POST request: Post \"http://multi2vec-clip:8080/vectorize\": context deadline exceeded (Client.Timeout exceeded while awaiting headers)\n",
      "e.g. Failed to import object with error: send POST request: Post \"http://multi2vec-clip:8080/vectorize\": context deadline exceeded (Client.Timeout exceeded while awaiting headers)\n",
      "e.g. Failed to import object with error: send POST request: Post \"http://multi2vec-clip:8080/vectorize\": context deadline exceeded (Client.Timeout exceeded while awaiting headers)\n",
      "e.g. Failed to import object with error: send POST request: Post \"http://multi2vec-clip:8080/vectorize\": context deadline exceeded (Client.Timeout exceeded while awaiting headers)\n",
      "e.g. Failed to import object with error: send POST request: Post \"http://multi2vec-clip:8080/vectorize\": context deadline exceeded (Client.Timeout exceeded while awaiting headers)\n",
      "e.g. Failed to import object with error: send POST request: Post \"http://multi2vec-clip:8080/vectorize\": context deadline exceeded (Client.Timeout exceeded while awaiting headers)\n",
      "e.g. Failed to import object with error: send POST request: Post \"http://multi2vec-clip:8080/vectorize\": context deadline exceeded (Client.Timeout exceeded while awaiting headers)\n",
      "e.g. Failed to import object with error: send POST request: Post \"http://multi2vec-clip:8080/vectorize\": context deadline exceeded (Client.Timeout exceeded while awaiting headers)\n",
      "e.g. Failed to import object with error: send POST request: Post \"http://multi2vec-clip:8080/vectorize\": context deadline exceeded (Client.Timeout exceeded while awaiting headers)\n",
      "e.g. Failed to import object with error: send POST request: Post \"http://multi2vec-clip:8080/vectorize\": context deadline exceeded (Client.Timeout exceeded while awaiting headers)\n",
      "e.g. Failed to import object with error: send POST request: Post \"http://multi2vec-clip:8080/vectorize\": context deadline exceeded (Client.Timeout exceeded while awaiting headers)\n",
      "e.g. Failed to import object with error: send POST request: Post \"http://multi2vec-clip:8080/vectorize\": context deadline exceeded (Client.Timeout exceeded while awaiting headers)\n",
      "e.g. Failed to import object with error: send POST request: Post \"http://multi2vec-clip:8080/vectorize\": context deadline exceeded (Client.Timeout exceeded while awaiting headers)\n",
      "e.g. Failed to import object with error: send POST request: Post \"http://multi2vec-clip:8080/vectorize\": context deadline exceeded (Client.Timeout exceeded while awaiting headers)\n",
      "e.g. Failed to import object with error: send POST request: Post \"http://multi2vec-clip:8080/vectorize\": context deadline exceeded (Client.Timeout exceeded while awaiting headers)\n",
      "e.g. Failed to import object with error: send POST request: Post \"http://multi2vec-clip:8080/vectorize\": context deadline exceeded (Client.Timeout exceeded while awaiting headers)\n",
      "e.g. Failed to import object with error: send POST request: Post \"http://multi2vec-clip:8080/vectorize\": context deadline exceeded (Client.Timeout exceeded while awaiting headers)\n",
      "e.g. Failed to import object with error: send POST request: Post \"http://multi2vec-clip:8080/vectorize\": context deadline exceeded (Client.Timeout exceeded while awaiting headers)\n"
     ]
    }
   ],
   "source": [
    "# Check for failed objects\n",
    "if len(movies.batch.failed_objects) > 0:\n",
    "    print(f\"Failed to import {len(movies.batch.failed_objects)} objects\")\n",
    "    for failed in movies.batch.failed_objects:\n",
    "        print(f\"e.g. Failed to import object with error: {failed.message}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interstellar 2014 157336\n",
      "Distance to query: 0.345\n",
      "\n",
      "Arrival 2016 329865\n",
      "Distance to query: 0.368\n",
      "\n",
      "Gravity 2013 49047\n",
      "Distance to query: 0.377\n",
      "\n",
      "Armageddon 1998 95\n",
      "Distance to query: 0.399\n",
      "\n",
      "The Dark Knight Rises 2012 49026\n",
      "Distance to query: 0.428\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import weaviate\n",
    "import weaviate.classes.query as wq\n",
    "import os\n",
    "\n",
    "\n",
    "# Instantiate your client (not shown). e.g.:\n",
    "# headers = {\"X-OpenAI-Api-Key\": os.getenv(\"OPENAI_APIKEY\")}  # Replace with your OpenAI API key\n",
    "# client = weaviate.connect_to_local(headers=headers)\n",
    "\n",
    "\n",
    "def url_to_base64(url):\n",
    "    import requests\n",
    "    import base64\n",
    "\n",
    "    image_response = requests.get(url)\n",
    "    content = image_response.content\n",
    "    return base64.b64encode(content).decode(\"utf-8\")\n",
    "\n",
    "\n",
    "# Get the collection\n",
    "movies = client.collections.get(\"MovieMM\")\n",
    "\n",
    "# Perform query\n",
    "src_img_path = \"https://github.com/weaviate-tutorials/edu-datasets/blob/main/img/International_Space_Station_after_undocking_of_STS-132.jpg?raw=true\"  # Space station pic\n",
    "query_b64 = url_to_base64(src_img_path)\n",
    "\n",
    "response = movies.query.near_image(\n",
    "    near_image=query_b64,\n",
    "    limit=5,\n",
    "    return_metadata=wq.MetadataQuery(distance=True),\n",
    "    return_properties=[\n",
    "        \"title\",\n",
    "        \"release_date\",\n",
    "        \"tmdb_id\",\n",
    "        \"poster\",\n",
    "    ],  # To include the poster property in the response (`blob` properties are not returned by default)\n",
    ")\n",
    "\n",
    "# Inspect the response\n",
    "for o in response.objects:\n",
    "    print(\n",
    "        o.properties[\"title\"],\n",
    "        o.properties[\"release_date\"].year,\n",
    "        o.properties[\"tmdb_id\"],\n",
    "    )  # Print the title and release year (note the release date is a datetime object)\n",
    "    print(\n",
    "        f\"Distance to query: {o.metadata.distance:.3f}\\n\"\n",
    "    )  # Print the distance of the object from the query\n",
    "\n",
    "# client.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "American History X 1998 73\n",
      "Distance to query: 0.637\n",
      "\n",
      "300 2007 1271\n",
      "Distance to query: 0.662\n",
      "\n",
      "Click 2006 9339\n",
      "Distance to query: 0.665\n",
      "\n",
      "I Am Legend 2007 6479\n",
      "Distance to query: 0.669\n",
      "\n",
      "Troy 2004 652\n",
      "Distance to query: 0.670\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import weaviate\n",
    "import weaviate.classes.query as wq\n",
    "import os\n",
    "\n",
    "\n",
    "# Instantiate your client (not shown). e.g.:\n",
    "# headers = {\"X-OpenAI-Api-Key\": os.getenv(\"OPENAI_APIKEY\")}  # Replace with your OpenAI API key\n",
    "# client = weaviate.connect_to_local(headers=headers)\n",
    "\n",
    "# Get the collection\n",
    "movies = client.collections.get(\"MovieMM\")\n",
    "\n",
    "# Perform query\n",
    "response = movies.query.near_text(\n",
    "    query=\"history\",\n",
    "    limit=5,\n",
    "    return_metadata=wq.MetadataQuery(distance=True),\n",
    "    return_properties=[\n",
    "        \"title\",\n",
    "        \"release_date\",\n",
    "        \"tmdb_id\",\n",
    "        \"poster\",\n",
    "    ],  # To include the poster property in the response (`blob` properties are not returned by default)\n",
    ")\n",
    "\n",
    "# Inspect the response\n",
    "for o in response.objects:\n",
    "    print(\n",
    "        o.properties[\"title\"],\n",
    "        o.properties[\"release_date\"].year,\n",
    "        o.properties[\"tmdb_id\"],\n",
    "    )  # Print the title and release year (note the release date is a datetime object)\n",
    "    print(\n",
    "        f\"Distance to query: {o.metadata.distance:.3f}\\n\"\n",
    "    )  # Print the distance of the object from the query\n",
    "\n",
    "# client.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keyword (BM25) Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "American History X 1998\n",
      "BM25 score: 2.669\n",
      "\n",
      "A Beautiful Mind 2001\n",
      "BM25 score: 1.870\n",
      "\n",
      "Legends of the Fall 1994\n",
      "BM25 score: 1.641\n",
      "\n",
      "Hacksaw Ridge 2016\n",
      "BM25 score: 1.534\n",
      "\n",
      "Night at the Museum 2006\n",
      "BM25 score: 1.509\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import weaviate\n",
    "import weaviate.classes.query as wq\n",
    "import os\n",
    "\n",
    "\n",
    "# Instantiate your client (not shown). e.g.:\n",
    "# headers = {\"X-OpenAI-Api-Key\": os.getenv(\"OPENAI_APIKEY\")}  # Replace with your OpenAI API key\n",
    "# client = weaviate.connect_to_local(headers=headers)\n",
    "\n",
    "# Get the collection\n",
    "movies = client.collections.get(\"MovieMM\")\n",
    "\n",
    "# Perform query\n",
    "response = movies.query.bm25(\n",
    "    query=\"history\", limit=5, return_metadata=wq.MetadataQuery(score=True)\n",
    ")\n",
    "\n",
    "# Inspect the response\n",
    "for o in response.objects:\n",
    "    print(\n",
    "        o.properties[\"title\"], o.properties[\"release_date\"].year\n",
    "    )  # Print the title and release year (note the release date is a datetime object)\n",
    "    print(\n",
    "        f\"BM25 score: {o.metadata.score:.3f}\\n\"\n",
    "    )  # Print the BM25 score of the object from the query\n",
    "\n",
    "# client.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hybrid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "American History X 1998\n",
      "Hybrid score: 1.000\n",
      "\n",
      "300 2007\n",
      "Hybrid score: 0.394\n",
      "\n",
      "Click 2006\n",
      "Hybrid score: 0.354\n",
      "\n",
      "I Am Legend 2007\n",
      "Hybrid score: 0.304\n",
      "\n",
      "Troy 2004\n",
      "Hybrid score: 0.289\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import weaviate\n",
    "import weaviate.classes.query as wq\n",
    "import os\n",
    "\n",
    "\n",
    "# Instantiate your client (not shown). e.g.:\n",
    "# headers = {\"X-OpenAI-Api-Key\": os.getenv(\"OPENAI_APIKEY\")}  # Replace with your OpenAI API key\n",
    "# client = weaviate.connect_to_local(headers=headers)\n",
    "\n",
    "# Get the collection\n",
    "movies = client.collections.get(\"MovieMM\")\n",
    "\n",
    "# Perform query\n",
    "response = movies.query.hybrid(\n",
    "    query=\"history\", limit=5, return_metadata=wq.MetadataQuery(score=True)\n",
    ")\n",
    "\n",
    "# Inspect the response\n",
    "for o in response.objects:\n",
    "    print(\n",
    "        o.properties[\"title\"], o.properties[\"release_date\"].year\n",
    "    )  # Print the title and release year (note the release date is a datetime object)\n",
    "    print(\n",
    "        f\"Hybrid score: {o.metadata.score:.3f}\\n\"\n",
    "    )  # Print the hybrid search score of the object from the query\n",
    "\n",
    "# client.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtered Text Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Free Guy 2021\n",
      "Distance to query: 0.653\n",
      "\n",
      "Onward 2020\n",
      "Distance to query: 0.666\n",
      "\n",
      "Elemental 2023\n",
      "Distance to query: 0.669\n",
      "\n",
      "Everything Everywhere All at Once 2022\n",
      "Distance to query: 0.673\n",
      "\n",
      "Tenet 2020\n",
      "Distance to query: 0.676\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chris/anaconda3/envs/weaviateRAG/lib/python3.11/site-packages/weaviate/warnings.py:202: UserWarning: Con002: You are inserting the datetime object 2020-01-01 00:00:00 without a timezone. The timezone will be set to UTC.\n",
      "            To use a different timezone, specify it in the datetime object. For example:\n",
      "            datetime.datetime(2021, 1, 1, 0, 0, 0, tzinfo=datetime.timezone(-datetime.timedelta(hours=2))).isoformat() = 2021-01-01T00:00:00-02:00\n",
      "            \n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import weaviate\n",
    "import weaviate.classes.query as wq\n",
    "import os\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "# Instantiate your client (not shown). e.g.:\n",
    "# headers = {\"X-OpenAI-Api-Key\": os.getenv(\"OPENAI_APIKEY\")}  # Replace with your OpenAI API key\n",
    "# client = weaviate.connect_to_local(headers=headers)\n",
    "\n",
    "# Get the collection\n",
    "movies = client.collections.get(\"MovieMM\")\n",
    "\n",
    "# Perform query\n",
    "response = movies.query.near_text(\n",
    "    query=\"dystopian future\",\n",
    "    limit=5,\n",
    "    return_metadata=wq.MetadataQuery(distance=True),\n",
    "    filters=wq.Filter.by_property(\"release_date\").greater_than(datetime(2020, 1, 1)),\n",
    ")\n",
    "\n",
    "# Inspect the response\n",
    "for o in response.objects:\n",
    "    print(\n",
    "        o.properties[\"title\"], o.properties[\"release_date\"].year\n",
    "    )  # Print the title and release year (note the release date is a datetime object)\n",
    "    print(\n",
    "        f\"Distance to query: {o.metadata.distance:.3f}\\n\"\n",
    "    )  # Print the distance of the object from the query\n",
    "\n",
    "# client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "weaviateRAG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
