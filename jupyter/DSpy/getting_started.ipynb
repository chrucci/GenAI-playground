{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dspy\n",
    "import os\n",
    "import openai\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../..\")\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "_ = load_dotenv(find_dotenv())  # read local .env file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that the env is configured correctly\n",
    "\n",
    "This getting started notebook can be found at: https://dspy-docs.vercel.app/docs/quick-start/minimal-example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7473/7473 [00:00<00:00, 70764.09it/s]\n",
      "100%|██████████| 1319/1319 [00:00<00:00, 50693.07it/s]\n"
     ]
    }
   ],
   "source": [
    "import dspy\n",
    "from dspy.datasets.gsm8k import GSM8K, gsm8k_metric\n",
    "\n",
    "# Set up the LM.\n",
    "turbo = dspy.OpenAI(\n",
    "    model=\"gpt-3.5-turbo-instruct\", max_tokens=250, api_key=os.environ[\"OPENAI_API_KEY\"]\n",
    ")\n",
    "dspy.settings.configure(lm=turbo)\n",
    "\n",
    "# Load math questions from the GSM8K dataset.\n",
    "gsm8k = GSM8K()\n",
    "gsm8k_trainset, gsm8k_devset = gsm8k.train[:10], gsm8k.dev[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example({'question': \"The result from the 40-item Statistics exam Marion and Ella took already came out. Ella got 4 incorrect answers while Marion got 6 more than half the score of Ella. What is Marion's score?\", 'gold_reasoning': \"Ella's score is 40 items - 4 items = <<40-4=36>>36 items. Half of Ella's score is 36 items / 2 = <<36/2=18>>18 items. So, Marion's score is 18 items + 6 items = <<18+6=24>>24 items.\", 'answer': '24'}) (input_keys={'question'})\n"
     ]
    }
   ],
   "source": [
    "print(gsm8k_trainset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CoT(dspy.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.prog = dspy.ChainOfThought(\"question -> answer\")\n",
    "\n",
    "    def forward(self, question):\n",
    "        return self.prog(question=question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [01:34<04:56, 42.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to run or to evaluate example Example({'question': 'Bridget counted 14 shooting stars in the night sky.  Reginald counted two fewer shooting stars than did Bridget, but Sam counted four more shooting stars than did Reginald.  How many more shooting stars did Sam count in the night sky than was the average number of shooting stars observed for the three of them?', 'gold_reasoning': 'Reginald counted two fewer shooting stars than did Bridget, or a total of 14-2=<<14-2=12>>12 shooting stars. Sam counted 4 more shooting stars than did Reginald, or a total of 12+4=16 shooting stars. The average number of shooting stars observed for the three of them was (14+12+16)/3 = <<14=14>>14 shooting stars. Thus, Sam counted 16-14=2 more shooting stars than was the average number of shooting stars observed for the three of them.', 'answer': '2'}) (input_keys={'question'}) with <function gsm8k_metric at 0x7fd65d5668e0> due to The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID req_42ddfaa9280d40d54f113dc15afeddeb in your message.) {\n",
      "  \"error\": {\n",
      "    \"message\": \"The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID req_42ddfaa9280d40d54f113dc15afeddeb in your message.)\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID req_42ddfaa9280d40d54f113dc15afeddeb in your message.)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Tue, 18 Jun 2024 02:02:21 GMT', 'Content-Type': 'application/json', 'Content-Length': '370', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-model': 'gpt-3.5-turbo-instruct', 'openai-organization': 'user-eukqux4q98vtbh1u7ytbko9k', 'openai-processing-ms': '90209', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '3500', 'x-ratelimit-limit-tokens': '90000', 'x-ratelimit-remaining-requests': '3499', 'x-ratelimit-remaining-tokens': '89434', 'x-ratelimit-reset-requests': '17ms', 'x-ratelimit-reset-tokens': '376ms', 'x-request-id': 'req_42ddfaa9280d40d54f113dc15afeddeb', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '8957b02a18244cde-BOS', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [01:38<01:05, 16.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 4 full traces after 7 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from dspy.teleprompt import BootstrapFewShot\n",
    "\n",
    "# Set up the optimizer: we want to \"bootstrap\" (i.e., self-generate) 4-shot examples of our CoT program.\n",
    "config = dict(max_bootstrapped_demos=4, max_labeled_demos=4)\n",
    "\n",
    "# Optimize! Use the `gsm8k_metric` here. In general, the metric is going to tell the optimizer how well it's doing.\n",
    "teleprompter = BootstrapFewShot(metric=gsm8k_metric, **config)\n",
    "optimized_cot = teleprompter.compile(CoT(), trainset=gsm8k_trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 8.0 / 10  (80.0): 100%|██████████| 10/10 [01:32<00:00,  9.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for example in dev set: \t\t The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID req_942434b74056b0a2a936f9c70d0d5435 in your message.) {\n",
      "  \"error\": {\n",
      "    \"message\": \"The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID req_942434b74056b0a2a936f9c70d0d5435 in your message.)\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID req_942434b74056b0a2a936f9c70d0d5435 in your message.)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Tue, 18 Jun 2024 02:04:56 GMT', 'Content-Type': 'application/json', 'Content-Length': '370', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-model': 'gpt-3.5-turbo-instruct', 'openai-organization': 'user-eukqux4q98vtbh1u7ytbko9k', 'openai-processing-ms': '90195', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '3500', 'x-ratelimit-limit-tokens': '90000', 'x-ratelimit-remaining-requests': '3499', 'x-ratelimit-remaining-tokens': '86848', 'x-ratelimit-reset-requests': '17ms', 'x-ratelimit-reset-tokens': '2.101s', 'x-request-id': 'req_942434b74056b0a2a936f9c70d0d5435', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '8957b3f27c333b94-BOS', 'alt-svc': 'h3=\":443\"; ma=86400'}\n",
      "Average Metric: 8.0 / 10  (80.0%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "80.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dspy.evaluate import Evaluate\n",
    "\n",
    "# Set up the evaluator, which can be used multiple times.\n",
    "evaluate = Evaluate(\n",
    "    devset=gsm8k_devset,\n",
    "    metric=gsm8k_metric,\n",
    "    num_threads=4,\n",
    "    display_progress=True,\n",
    "    display_table=0,\n",
    ")\n",
    "\n",
    "# Evaluate our `optimized_cot` program.\n",
    "evaluate(optimized_cot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "Given the fields `question`, produce the fields `answer`.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Reasoning: Let's think step by step in order to ${produce the answer}. We ...\n",
      "Answer: ${answer}\n",
      "\n",
      "---\n",
      "\n",
      "Question: The result from the 40-item Statistics exam Marion and Ella took already came out. Ella got 4 incorrect answers while Marion got 6 more than half the score of Ella. What is Marion's score?\n",
      "Reasoning: Let's think step by step in order to find Marion's score. We know that Ella got 4 incorrect answers, which means she got 36 correct answers out of 40. We also know that Marion got 6 more than half of Ella's score, which is 6 more than 36/2 = 18. Therefore, Marion's score is 18 + 6 = 24.\n",
      "Answer: 24\n",
      "\n",
      "---\n",
      "\n",
      "Question: Sarah buys 20 pencils on Monday. Then she buys 18 more pencils on Tuesday. On Wednesday she buys triple the number of pencils she did on Tuesday. How many pencils does she have?\n",
      "Reasoning: Let's think step by step in order to find the total number of pencils Sarah has. First, we know that she bought 20 pencils on Monday and 18 more on Tuesday, making a total of 38 pencils. Then, on Wednesday, she bought triple the number of pencils she did on Tuesday, which is 3 times 18, or 54 pencils. Therefore, the total number of pencils Sarah has is 38 + 54 = 92.\n",
      "Answer: 92\n",
      "\n",
      "---\n",
      "\n",
      "Question: Rookie police officers have to buy duty shoes at the full price of $85, but officers who have served at least a year get a 20% discount. Officers who have served at least three years get an additional 25% off the discounted price. How much does an officer who has served at least three years have to pay for shoes?\n",
      "Reasoning: Let's think step by step in order to calculate the final price. First, we calculate the discounted price for an officer who has served at least a year. This is 85 * 0.8 = 68. Then, we calculate the additional discount for an officer who has served at least three years. This is 68 * 0.75 = 51. Finally, the officer has to pay 51 dollars for the shoes.\n",
      "Answer: $51\n",
      "\n",
      "---\n",
      "\n",
      "Question: The average score on last week's Spanish test was 90. Marco scored 10% less than the average test score and Margaret received 5 more points than Marco. What score did Margaret receive on her test?\n",
      "Reasoning: Let's think step by step in order to find Margaret's score. First, we know that Marco scored 10% less than the average test score, which means he scored 90 - (90 * 0.10) = 81 points. Next, we know that Margaret received 5 more points than Marco, so her score is 81 + 5 = 86 points.\n",
      "Answer: 86\n",
      "\n",
      "---\n",
      "\n",
      "Question: Trey is raising money for a new bike that costs $112. He plans to spend the next two weeks selling bracelets for $1 each. On average, how many bracelets does he need to sell each day?\n",
      "Reasoning: Let's think step by step in order to\u001b[32m calculate the average number of bracelets Trey needs to sell each day. First, we need to calculate the total amount of money Trey needs to raise, which is $112. Then, we divide this amount by the number of days he has to sell the bracelets, which is 14 days. Therefore, Trey needs to sell $112 / 14 = 8 bracelets each day.\n",
      "Answer: 8 bracelets\u001b[0m\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "turbo.inspect_history(n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dspy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
